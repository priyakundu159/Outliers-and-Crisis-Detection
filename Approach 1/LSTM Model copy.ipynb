{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9n/nyfs9h7n2lsfs0vd2lq0589h0000gn/T/ipykernel_9320/2206832580.py:22: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method='ffill', inplace=True)\n",
      "/var/folders/9n/nyfs9h7n2lsfs0vd2lq0589h0000gn/T/ipykernel_9320/2206832580.py:23: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method='bfill', inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 - 2s - 901ms/step - loss: 0.2544 - val_loss: 0.1141\n",
      "Epoch 2/100\n",
      "2/2 - 0s - 61ms/step - loss: 0.1121 - val_loss: 0.0232\n",
      "Epoch 3/100\n",
      "2/2 - 0s - 60ms/step - loss: 0.0417 - val_loss: 0.0407\n",
      "Epoch 4/100\n",
      "2/2 - 0s - 63ms/step - loss: 0.0276 - val_loss: 0.0166\n",
      "Epoch 5/100\n",
      "2/2 - 0s - 60ms/step - loss: 0.0261 - val_loss: 0.0175\n",
      "Epoch 6/100\n",
      "2/2 - 0s - 59ms/step - loss: 0.0224 - val_loss: 0.0165\n",
      "Epoch 7/100\n",
      "2/2 - 0s - 58ms/step - loss: 0.0196 - val_loss: 0.0053\n",
      "Epoch 8/100\n",
      "2/2 - 0s - 62ms/step - loss: 0.0124 - val_loss: 0.0034\n",
      "Epoch 9/100\n",
      "2/2 - 0s - 63ms/step - loss: 0.0096 - val_loss: 0.0051\n",
      "Epoch 10/100\n",
      "2/2 - 0s - 62ms/step - loss: 0.0079 - val_loss: 0.0096\n",
      "Epoch 11/100\n",
      "2/2 - 0s - 61ms/step - loss: 0.0081 - val_loss: 0.0030\n",
      "Epoch 12/100\n",
      "2/2 - 0s - 61ms/step - loss: 0.0072 - val_loss: 0.0022\n",
      "Epoch 13/100\n",
      "2/2 - 0s - 58ms/step - loss: 0.0059 - val_loss: 0.0026\n",
      "Epoch 14/100\n",
      "2/2 - 0s - 58ms/step - loss: 0.0049 - val_loss: 9.1373e-04\n",
      "Epoch 15/100\n",
      "2/2 - 0s - 59ms/step - loss: 0.0044 - val_loss: 8.2002e-04\n",
      "Epoch 16/100\n",
      "2/2 - 0s - 62ms/step - loss: 0.0041 - val_loss: 0.0017\n",
      "Epoch 17/100\n",
      "2/2 - 0s - 59ms/step - loss: 0.0039 - val_loss: 0.0010\n",
      "Epoch 18/100\n",
      "2/2 - 0s - 61ms/step - loss: 0.0040 - val_loss: 7.9466e-04\n",
      "Epoch 19/100\n",
      "2/2 - 0s - 62ms/step - loss: 0.0041 - val_loss: 0.0014\n",
      "Epoch 20/100\n",
      "2/2 - 0s - 61ms/step - loss: 0.0032 - val_loss: 7.4960e-04\n",
      "Epoch 21/100\n",
      "2/2 - 0s - 59ms/step - loss: 0.0038 - val_loss: 0.0017\n",
      "Epoch 22/100\n",
      "2/2 - 0s - 59ms/step - loss: 0.0035 - val_loss: 0.0010\n",
      "Epoch 23/100\n",
      "2/2 - 0s - 60ms/step - loss: 0.0029 - val_loss: 5.8244e-04\n",
      "Epoch 24/100\n",
      "2/2 - 0s - 58ms/step - loss: 0.0027 - val_loss: 8.2459e-04\n",
      "Epoch 25/100\n",
      "2/2 - 0s - 60ms/step - loss: 0.0033 - val_loss: 5.4231e-04\n",
      "Epoch 26/100\n",
      "2/2 - 0s - 59ms/step - loss: 0.0032 - val_loss: 5.7993e-04\n",
      "Epoch 27/100\n",
      "2/2 - 0s - 57ms/step - loss: 0.0029 - val_loss: 0.0015\n",
      "Epoch 28/100\n",
      "2/2 - 0s - 56ms/step - loss: 0.0036 - val_loss: 5.5025e-04\n",
      "Epoch 29/100\n",
      "2/2 - 0s - 56ms/step - loss: 0.0032 - val_loss: 5.1542e-04\n",
      "Epoch 30/100\n",
      "2/2 - 0s - 59ms/step - loss: 0.0026 - val_loss: 0.0011\n",
      "Epoch 31/100\n",
      "2/2 - 0s - 57ms/step - loss: 0.0031 - val_loss: 5.2824e-04\n",
      "Epoch 32/100\n",
      "2/2 - 0s - 58ms/step - loss: 0.0031 - val_loss: 5.0129e-04\n",
      "Epoch 33/100\n",
      "2/2 - 0s - 57ms/step - loss: 0.0026 - val_loss: 9.3674e-04\n",
      "Epoch 34/100\n",
      "2/2 - 0s - 56ms/step - loss: 0.0033 - val_loss: 5.2255e-04\n",
      "Epoch 35/100\n",
      "2/2 - 0s - 55ms/step - loss: 0.0032 - val_loss: 6.1440e-04\n",
      "Epoch 36/100\n",
      "2/2 - 0s - 56ms/step - loss: 0.0026 - val_loss: 0.0011\n",
      "Epoch 37/100\n",
      "2/2 - 0s - 56ms/step - loss: 0.0030 - val_loss: 5.3019e-04\n",
      "Epoch 38/100\n",
      "2/2 - 0s - 56ms/step - loss: 0.0028 - val_loss: 7.5094e-04\n",
      "Epoch 39/100\n",
      "2/2 - 0s - 59ms/step - loss: 0.0031 - val_loss: 6.4481e-04\n",
      "Epoch 40/100\n",
      "2/2 - 0s - 59ms/step - loss: 0.0030 - val_loss: 5.0449e-04\n",
      "Epoch 41/100\n",
      "2/2 - 0s - 59ms/step - loss: 0.0035 - val_loss: 8.3441e-04\n",
      "Epoch 42/100\n",
      "2/2 - 0s - 62ms/step - loss: 0.0027 - val_loss: 4.9513e-04\n",
      "Epoch 43/100\n",
      "2/2 - 0s - 60ms/step - loss: 0.0033 - val_loss: 7.0433e-04\n",
      "Epoch 44/100\n",
      "2/2 - 0s - 79ms/step - loss: 0.0029 - val_loss: 5.4404e-04\n",
      "Epoch 45/100\n",
      "2/2 - 0s - 60ms/step - loss: 0.0025 - val_loss: 5.9917e-04\n",
      "Epoch 46/100\n",
      "2/2 - 0s - 58ms/step - loss: 0.0030 - val_loss: 5.8995e-04\n",
      "Epoch 47/100\n",
      "2/2 - 0s - 57ms/step - loss: 0.0027 - val_loss: 5.0922e-04\n",
      "Epoch 48/100\n",
      "2/2 - 0s - 58ms/step - loss: 0.0028 - val_loss: 8.8278e-04\n",
      "Epoch 49/100\n",
      "2/2 - 0s - 60ms/step - loss: 0.0032 - val_loss: 5.1339e-04\n",
      "Epoch 50/100\n",
      "2/2 - 0s - 59ms/step - loss: 0.0029 - val_loss: 6.2378e-04\n",
      "Epoch 51/100\n",
      "2/2 - 0s - 77ms/step - loss: 0.0025 - val_loss: 8.6105e-04\n",
      "Epoch 52/100\n",
      "2/2 - 0s - 60ms/step - loss: 0.0028 - val_loss: 4.8943e-04\n",
      "Epoch 53/100\n",
      "2/2 - 0s - 66ms/step - loss: 0.0030 - val_loss: 6.6127e-04\n",
      "Epoch 54/100\n",
      "2/2 - 0s - 60ms/step - loss: 0.0029 - val_loss: 6.1028e-04\n",
      "Epoch 55/100\n",
      "2/2 - 0s - 59ms/step - loss: 0.0031 - val_loss: 5.0048e-04\n",
      "Epoch 56/100\n",
      "2/2 - 0s - 60ms/step - loss: 0.0030 - val_loss: 6.4096e-04\n",
      "Epoch 57/100\n",
      "2/2 - 0s - 60ms/step - loss: 0.0032 - val_loss: 4.9643e-04\n",
      "Epoch 58/100\n",
      "2/2 - 0s - 59ms/step - loss: 0.0032 - val_loss: 5.0589e-04\n",
      "Epoch 59/100\n",
      "2/2 - 0s - 58ms/step - loss: 0.0027 - val_loss: 6.8376e-04\n",
      "Epoch 60/100\n",
      "2/2 - 0s - 59ms/step - loss: 0.0032 - val_loss: 4.8661e-04\n",
      "Epoch 61/100\n",
      "2/2 - 0s - 60ms/step - loss: 0.0028 - val_loss: 6.7503e-04\n",
      "Epoch 62/100\n",
      "2/2 - 0s - 61ms/step - loss: 0.0037 - val_loss: 6.8515e-04\n",
      "Epoch 63/100\n",
      "2/2 - 0s - 60ms/step - loss: 0.0031 - val_loss: 5.2310e-04\n",
      "Epoch 64/100\n",
      "2/2 - 0s - 59ms/step - loss: 0.0030 - val_loss: 0.0012\n",
      "Epoch 65/100\n",
      "2/2 - 0s - 60ms/step - loss: 0.0030 - val_loss: 5.4805e-04\n",
      "Epoch 66/100\n",
      "2/2 - 0s - 60ms/step - loss: 0.0030 - val_loss: 9.5561e-04\n",
      "Epoch 67/100\n",
      "2/2 - 0s - 59ms/step - loss: 0.0027 - val_loss: 6.2090e-04\n",
      "Epoch 68/100\n",
      "2/2 - 0s - 59ms/step - loss: 0.0028 - val_loss: 6.3968e-04\n",
      "Epoch 69/100\n",
      "2/2 - 0s - 59ms/step - loss: 0.0029 - val_loss: 7.7163e-04\n",
      "Epoch 70/100\n",
      "2/2 - 0s - 59ms/step - loss: 0.0026 - val_loss: 5.4196e-04\n",
      "Epoch 71/100\n",
      "2/2 - 0s - 59ms/step - loss: 0.0024 - val_loss: 7.4306e-04\n",
      "Epoch 72/100\n",
      "2/2 - 0s - 59ms/step - loss: 0.0026 - val_loss: 4.9975e-04\n",
      "Epoch 73/100\n",
      "2/2 - 0s - 59ms/step - loss: 0.0029 - val_loss: 5.9738e-04\n",
      "Epoch 74/100\n",
      "2/2 - 0s - 59ms/step - loss: 0.0025 - val_loss: 7.1211e-04\n",
      "Epoch 75/100\n",
      "2/2 - 0s - 60ms/step - loss: 0.0028 - val_loss: 5.6088e-04\n",
      "Epoch 76/100\n",
      "2/2 - 0s - 59ms/step - loss: 0.0028 - val_loss: 5.3673e-04\n",
      "Epoch 77/100\n",
      "2/2 - 0s - 59ms/step - loss: 0.0024 - val_loss: 7.7191e-04\n",
      "Epoch 78/100\n",
      "2/2 - 0s - 59ms/step - loss: 0.0026 - val_loss: 5.3193e-04\n",
      "Epoch 79/100\n",
      "2/2 - 0s - 58ms/step - loss: 0.0025 - val_loss: 7.1919e-04\n",
      "Epoch 80/100\n",
      "2/2 - 0s - 59ms/step - loss: 0.0028 - val_loss: 4.9866e-04\n",
      "Epoch 81/100\n",
      "2/2 - 0s - 59ms/step - loss: 0.0026 - val_loss: 6.1740e-04\n",
      "Epoch 82/100\n",
      "2/2 - 0s - 57ms/step - loss: 0.0030 - val_loss: 5.7644e-04\n",
      "Epoch 83/100\n",
      "2/2 - 0s - 59ms/step - loss: 0.0029 - val_loss: 5.1322e-04\n",
      "Epoch 84/100\n",
      "2/2 - 0s - 59ms/step - loss: 0.0024 - val_loss: 9.4930e-04\n",
      "Epoch 85/100\n",
      "2/2 - 0s - 60ms/step - loss: 0.0029 - val_loss: 4.8593e-04\n",
      "Epoch 86/100\n",
      "2/2 - 0s - 61ms/step - loss: 0.0028 - val_loss: 0.0012\n",
      "Epoch 87/100\n",
      "2/2 - 0s - 59ms/step - loss: 0.0033 - val_loss: 4.8517e-04\n",
      "Epoch 88/100\n",
      "2/2 - 0s - 59ms/step - loss: 0.0031 - val_loss: 4.9501e-04\n",
      "Epoch 89/100\n",
      "2/2 - 0s - 59ms/step - loss: 0.0025 - val_loss: 0.0013\n",
      "Epoch 90/100\n",
      "2/2 - 0s - 58ms/step - loss: 0.0031 - val_loss: 5.5874e-04\n",
      "Epoch 91/100\n",
      "2/2 - 0s - 59ms/step - loss: 0.0033 - val_loss: 0.0010\n",
      "Epoch 92/100\n",
      "2/2 - 0s - 58ms/step - loss: 0.0029 - val_loss: 4.7904e-04\n",
      "Epoch 93/100\n",
      "2/2 - 0s - 60ms/step - loss: 0.0031 - val_loss: 6.2990e-04\n",
      "Epoch 94/100\n",
      "2/2 - 0s - 61ms/step - loss: 0.0025 - val_loss: 7.5187e-04\n",
      "Epoch 95/100\n",
      "2/2 - 0s - 59ms/step - loss: 0.0029 - val_loss: 5.0217e-04\n",
      "Epoch 96/100\n",
      "2/2 - 0s - 59ms/step - loss: 0.0028 - val_loss: 8.9086e-04\n",
      "Epoch 97/100\n",
      "2/2 - 0s - 59ms/step - loss: 0.0034 - val_loss: 4.9446e-04\n",
      "Epoch 98/100\n",
      "2/2 - 0s - 59ms/step - loss: 0.0030 - val_loss: 5.6908e-04\n",
      "Epoch 99/100\n",
      "2/2 - 0s - 60ms/step - loss: 0.0031 - val_loss: 7.1611e-04\n",
      "Epoch 100/100\n",
      "2/2 - 0s - 60ms/step - loss: 0.0029 - val_loss: 4.7753e-04\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 169ms/step\n",
      "Model training complete and predictions made.\n"
     ]
    }
   ],
   "source": [
    "def prepare_sequences(df):\n",
    "    sequences = []\n",
    "    labels = []\n",
    "    \n",
    "    unique_ids = df['outlier_id'].unique()\n",
    "    \n",
    "    for oid in unique_ids:\n",
    "        prior_data = df[(df['outlier_id'] == oid) & (df['day type'].isin(['prior day', 'outlier day']))]['c'].values\n",
    "        post_data = df[(df['outlier_id'] == oid) & (df['day type'] == 'post day')]['c'].values\n",
    "        \n",
    "        if len(prior_data) >= 72 and len(post_data) >= 72:  # Ensure full sequences\n",
    "            sequences.append(prior_data[-72:])\n",
    "            labels.append(post_data[:72])  # Only the first 3 post days are needed\n",
    "            \n",
    "    return np.array(sequences), np.array(labels)\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv('USDCHF_hourly.csv')  # Make sure to load your actual data file\n",
    "\n",
    "# Clean the data - Handle missing values.\n",
    "df.drop(columns= ['prev_close', 'returns', 'day'], inplace=True)\n",
    "df.fillna(method='ffill', inplace=True)\n",
    "df.fillna(method='bfill', inplace=True)\n",
    "\n",
    "# Normalize each sequence\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "df['c'] = scaler.fit_transform(df[['c']])\n",
    "\n",
    "X, y = prepare_sequences(df)\n",
    "\n",
    "# Reshape for LSTM input\n",
    "X = X.reshape((X.shape[0], X.shape[1], 1))\n",
    "y = y.reshape((y.shape[0], 72))  # Predicting only the first 3 days of post day\n",
    "\n",
    "# Define the LSTM model\n",
    "model = Sequential([\n",
    "    LSTM(50, return_sequences=True, input_shape=(72, 1)),  # Input sequences are 72 time steps\n",
    "    LSTM(50),\n",
    "    Dense(72)  # Output 3 predictions\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.01), loss='mean_squared_error')\n",
    "\n",
    "# Split data into train and test sets\n",
    "train_size = int(len(X) * 0.80)\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, batch_size=64, verbose=2)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Optionally, scale back the predictions to the original scale\n",
    "predictions = scaler.inverse_transform(predictions)\n",
    "y_test = scaler.inverse_transform(y_test)\n",
    "\n",
    "print(\"Model training complete and predictions made.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 5.2965785380431166e-05\n",
      "Mean Absolute Error: 0.00544120123938871\n",
      "Root Mean Squared Error: 0.0072777596401936194\n",
      "R-squared: 0.9394305414867303\n"
     ]
    }
   ],
   "source": [
    "# Calculate MSE and MAE\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "mae = mean_absolute_error(y_test, predictions)\n",
    "rmse = np.sqrt(mse)  # Calculate RMSE\n",
    "r2 = r2_score(y_test, predictions)  # Calculate R^2 score\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"Mean Absolute Error: {mae}\")\n",
    "print(f\"Root Mean Squared Error: {rmse}\")\n",
    "print(f\"R-squared: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import LSTM, Dense\n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# # Function to prepare sequences for training\n",
    "# def prepare_sequences_train(df):\n",
    "#     sequences = []\n",
    "#     labels = []\n",
    "    \n",
    "#     unique_ids = df['outlier_id'].unique()\n",
    "    \n",
    "#     for oid in unique_ids:\n",
    "#         prior_data = df[(df['outlier_id'] == oid) & (df['day type'] == 'prior day')]['c'].values\n",
    "#         post_data = df[(df['outlier_id'] == oid) & (df['day type'] == 'post day')]['c'].values\n",
    "        \n",
    "#         if len(prior_data) == 72 and len(post_data) >= 72:\n",
    "#             sequences.append(prior_data)\n",
    "#             labels.append(post_data[:72])\n",
    "#         else:\n",
    "#             print(f\"Skipping outlier_id {oid} due to insufficient prior or post data\")\n",
    "#     return np.array(sequences), np.array(labels)\n",
    "\n",
    "# # Load and prepare training data\n",
    "# def train_model(file_path):\n",
    "#     df_train = pd.read_csv(file_path) # Augmented Data csv file\n",
    "#     scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "#     df_train['c'] = scaler.fit_transform(df_train[['c']])\n",
    "    \n",
    "#     X_train, y_train = prepare_sequences_train(df_train)\n",
    "#     X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "#     y_train = y_train.reshape((y_train.shape[0], 72))\n",
    "    \n",
    "#     model = Sequential([\n",
    "#         LSTM(50, return_sequences=True, input_shape=(72, 1)),\n",
    "#         LSTM(50),\n",
    "#         Dense(72)\n",
    "#     ])\n",
    "#     model.compile(optimizer=Adam(learning_rate=0.01), loss='mean_squared_error')\n",
    "#     model.fit(X_train, y_train, epochs=100, batch_size=64, verbose=2)\n",
    "#     return model, scaler\n",
    "\n",
    "# # Function to prepare a single sequence for prediction\n",
    "# def prepare_sequence_predict(df_prior, scaler):\n",
    "#     prior_data = df_prior['c'].values # \"df_prior\" should be the dataframe containing prior day's data for the current outlier.\n",
    "#     prior_data = scaler.transform(prior_data.reshape(-1, 1)).flatten()\n",
    "#     return prior_data.reshape(1, 72, 1)\n",
    "\n",
    "# # Function to predict using the model\n",
    "# def predict(model, df_prior, scaler):\n",
    "#     X_test = prepare_sequence_predict(df_prior, scaler)\n",
    "#     predictions = model.predict(X_test)\n",
    "#     return scaler.inverse_transform(predictions.reshape(-1, 1))\n",
    "\n",
    "# # Function to validate predictions\n",
    "# def validate_predictions(predictions, df_post, scaler):\n",
    "#     post_data = df_post['c'].values[:72] # \"df_post\" should be the dataframe containing post day's data for the current outlier.\n",
    "#     post_data_scaled = scaler.transform(post_data.reshape(-1, 1)).flatten()\n",
    "    \n",
    "#     mse = mean_squared_error(post_data_scaled, predictions.flatten())\n",
    "#     mae = mean_absolute_error(post_data_scaled, predictions.flatten())\n",
    "#     rmse = np.sqrt(mse)\n",
    "#     r2 = r2_score(post_data_scaled, predictions.flatten())\n",
    "\n",
    "#     print(f\"Mean Squared Error: {mse}\")\n",
    "#     print(f\"Mean Absolute Error: {mae}\")\n",
    "#     print(f\"Root Mean Squared Error: {rmse}\")\n",
    "#     print(f\"R-squared: {r2}\")\n",
    "\n",
    "# # Example usage:\n",
    "# model, scaler = train_model('train_data.csv')\n",
    "# predictions = predict(model, df_prior, scaler)\n",
    "# validate_predictions(predictions, df_post, scaler)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
