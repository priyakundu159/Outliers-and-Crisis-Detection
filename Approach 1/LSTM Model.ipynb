{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9n/nyfs9h7n2lsfs0vd2lq0589h0000gn/T/ipykernel_7596/2003285864.py:29: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method='ffill', inplace=True)\n",
      "/var/folders/9n/nyfs9h7n2lsfs0vd2lq0589h0000gn/T/ipykernel_7596/2003285864.py:30: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method='bfill', inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 - 2s - 859ms/step - loss: 0.2837 - val_loss: 0.0835\n",
      "Epoch 2/100\n",
      "2/2 - 0s - 56ms/step - loss: 0.1049 - val_loss: 0.0271\n",
      "Epoch 3/100\n",
      "2/2 - 0s - 56ms/step - loss: 0.0362 - val_loss: 0.0382\n",
      "Epoch 4/100\n",
      "2/2 - 0s - 56ms/step - loss: 0.0258 - val_loss: 0.0185\n",
      "Epoch 5/100\n",
      "2/2 - 0s - 61ms/step - loss: 0.0350 - val_loss: 0.0594\n",
      "Epoch 6/100\n",
      "2/2 - 0s - 56ms/step - loss: 0.0346 - val_loss: 0.0090\n",
      "Epoch 7/100\n",
      "2/2 - 0s - 56ms/step - loss: 0.0206 - val_loss: 0.0055\n",
      "Epoch 8/100\n",
      "2/2 - 0s - 56ms/step - loss: 0.0196 - val_loss: 0.0121\n",
      "Epoch 9/100\n",
      "2/2 - 0s - 56ms/step - loss: 0.0146 - val_loss: 0.0193\n",
      "Epoch 10/100\n",
      "2/2 - 0s - 55ms/step - loss: 0.0110 - val_loss: 0.0030\n",
      "Epoch 11/100\n",
      "2/2 - 0s - 56ms/step - loss: 0.0060 - val_loss: 0.0022\n",
      "Epoch 12/100\n",
      "2/2 - 0s - 55ms/step - loss: 0.0079 - val_loss: 0.0014\n",
      "Epoch 13/100\n",
      "2/2 - 0s - 63ms/step - loss: 0.0054 - val_loss: 0.0022\n",
      "Epoch 14/100\n",
      "2/2 - 0s - 56ms/step - loss: 0.0044 - val_loss: 0.0026\n",
      "Epoch 15/100\n",
      "2/2 - 0s - 55ms/step - loss: 0.0037 - val_loss: 0.0011\n",
      "Epoch 16/100\n",
      "2/2 - 0s - 57ms/step - loss: 0.0029 - val_loss: 0.0010\n",
      "Epoch 17/100\n",
      "2/2 - 0s - 56ms/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 18/100\n",
      "2/2 - 0s - 58ms/step - loss: 0.0024 - val_loss: 7.8894e-04\n",
      "Epoch 19/100\n",
      "2/2 - 0s - 55ms/step - loss: 0.0023 - val_loss: 8.8448e-04\n",
      "Epoch 20/100\n",
      "2/2 - 0s - 58ms/step - loss: 0.0021 - val_loss: 7.7172e-04\n",
      "Epoch 21/100\n",
      "2/2 - 0s - 58ms/step - loss: 0.0033 - val_loss: 7.8365e-04\n",
      "Epoch 22/100\n",
      "2/2 - 0s - 58ms/step - loss: 0.0022 - val_loss: 7.0518e-04\n",
      "Epoch 23/100\n",
      "2/2 - 0s - 56ms/step - loss: 0.0031 - val_loss: 8.4183e-04\n",
      "Epoch 24/100\n",
      "2/2 - 0s - 55ms/step - loss: 0.0030 - val_loss: 8.7407e-04\n",
      "Epoch 25/100\n",
      "2/2 - 0s - 55ms/step - loss: 0.0018 - val_loss: 5.3755e-04\n",
      "Epoch 26/100\n",
      "2/2 - 0s - 54ms/step - loss: 0.0017 - val_loss: 4.6364e-04\n",
      "Epoch 27/100\n",
      "2/2 - 0s - 60ms/step - loss: 0.0017 - val_loss: 5.4578e-04\n",
      "Epoch 28/100\n",
      "2/2 - 0s - 55ms/step - loss: 0.0016 - val_loss: 4.2827e-04\n",
      "Epoch 29/100\n",
      "2/2 - 0s - 55ms/step - loss: 0.0026 - val_loss: 4.3860e-04\n",
      "Epoch 30/100\n",
      "2/2 - 0s - 55ms/step - loss: 0.0015 - val_loss: 5.2487e-04\n",
      "Epoch 31/100\n",
      "2/2 - 0s - 54ms/step - loss: 0.0026 - val_loss: 3.7896e-04\n",
      "Epoch 32/100\n",
      "2/2 - 0s - 56ms/step - loss: 0.0016 - val_loss: 3.6252e-04\n",
      "Epoch 33/100\n",
      "2/2 - 0s - 56ms/step - loss: 0.0026 - val_loss: 3.9098e-04\n",
      "Epoch 34/100\n",
      "2/2 - 0s - 57ms/step - loss: 0.0016 - val_loss: 3.5487e-04\n",
      "Epoch 35/100\n",
      "2/2 - 0s - 54ms/step - loss: 0.0018 - val_loss: 3.5597e-04\n",
      "Epoch 36/100\n",
      "2/2 - 0s - 55ms/step - loss: 0.0026 - val_loss: 3.3907e-04\n",
      "Epoch 37/100\n",
      "2/2 - 0s - 56ms/step - loss: 0.0025 - val_loss: 4.2167e-04\n",
      "Epoch 38/100\n",
      "2/2 - 0s - 54ms/step - loss: 0.0019 - val_loss: 3.8807e-04\n",
      "Epoch 39/100\n",
      "2/2 - 0s - 54ms/step - loss: 0.0026 - val_loss: 3.5387e-04\n",
      "Epoch 40/100\n",
      "2/2 - 0s - 54ms/step - loss: 0.0016 - val_loss: 3.6676e-04\n",
      "Epoch 41/100\n",
      "2/2 - 0s - 55ms/step - loss: 0.0025 - val_loss: 4.2620e-04\n",
      "Epoch 42/100\n",
      "2/2 - 0s - 56ms/step - loss: 0.0015 - val_loss: 3.5666e-04\n",
      "Epoch 43/100\n",
      "2/2 - 0s - 78ms/step - loss: 0.0015 - val_loss: 3.4820e-04\n",
      "Epoch 44/100\n",
      "2/2 - 0s - 75ms/step - loss: 0.0018 - val_loss: 4.1567e-04\n",
      "Epoch 45/100\n",
      "2/2 - 0s - 56ms/step - loss: 0.0028 - val_loss: 4.2347e-04\n",
      "Epoch 46/100\n",
      "2/2 - 0s - 72ms/step - loss: 0.0018 - val_loss: 3.6433e-04\n",
      "Epoch 47/100\n",
      "2/2 - 0s - 124ms/step - loss: 0.0028 - val_loss: 4.1425e-04\n",
      "Epoch 48/100\n",
      "2/2 - 0s - 60ms/step - loss: 0.0017 - val_loss: 4.4619e-04\n",
      "Epoch 49/100\n",
      "2/2 - 0s - 58ms/step - loss: 0.0027 - val_loss: 4.7247e-04\n",
      "Epoch 50/100\n",
      "2/2 - 0s - 56ms/step - loss: 0.0015 - val_loss: 3.8386e-04\n",
      "Epoch 51/100\n",
      "2/2 - 0s - 58ms/step - loss: 0.0015 - val_loss: 3.9733e-04\n",
      "Epoch 52/100\n",
      "2/2 - 0s - 57ms/step - loss: 0.0025 - val_loss: 3.7482e-04\n",
      "Epoch 53/100\n",
      "2/2 - 0s - 56ms/step - loss: 0.0025 - val_loss: 4.0638e-04\n",
      "Epoch 54/100\n",
      "2/2 - 0s - 59ms/step - loss: 0.0016 - val_loss: 3.7986e-04\n",
      "Epoch 55/100\n",
      "2/2 - 0s - 59ms/step - loss: 0.0027 - val_loss: 4.1756e-04\n",
      "Epoch 56/100\n",
      "2/2 - 0s - 57ms/step - loss: 0.0016 - val_loss: 4.2786e-04\n",
      "Epoch 57/100\n",
      "2/2 - 0s - 61ms/step - loss: 0.0030 - val_loss: 4.3173e-04\n",
      "Epoch 58/100\n",
      "2/2 - 0s - 59ms/step - loss: 0.0018 - val_loss: 3.5837e-04\n",
      "Epoch 59/100\n",
      "2/2 - 0s - 59ms/step - loss: 0.0027 - val_loss: 3.4952e-04\n",
      "Epoch 60/100\n",
      "2/2 - 0s - 60ms/step - loss: 0.0015 - val_loss: 3.9386e-04\n",
      "Epoch 61/100\n",
      "2/2 - 0s - 58ms/step - loss: 0.0026 - val_loss: 3.6012e-04\n",
      "Epoch 62/100\n",
      "2/2 - 0s - 57ms/step - loss: 0.0025 - val_loss: 3.9799e-04\n",
      "Epoch 63/100\n",
      "2/2 - 0s - 62ms/step - loss: 0.0025 - val_loss: 4.7729e-04\n",
      "Epoch 64/100\n",
      "2/2 - 0s - 59ms/step - loss: 0.0015 - val_loss: 3.6338e-04\n",
      "Epoch 65/100\n",
      "2/2 - 0s - 59ms/step - loss: 0.0025 - val_loss: 3.6560e-04\n",
      "Epoch 66/100\n",
      "2/2 - 0s - 56ms/step - loss: 0.0029 - val_loss: 3.6764e-04\n",
      "Epoch 67/100\n",
      "2/2 - 0s - 58ms/step - loss: 0.0016 - val_loss: 3.6571e-04\n",
      "Epoch 68/100\n",
      "2/2 - 0s - 69ms/step - loss: 0.0015 - val_loss: 3.8930e-04\n",
      "Epoch 69/100\n",
      "2/2 - 0s - 56ms/step - loss: 0.0015 - val_loss: 3.7087e-04\n",
      "Epoch 70/100\n",
      "2/2 - 0s - 56ms/step - loss: 0.0015 - val_loss: 5.1904e-04\n",
      "Epoch 71/100\n",
      "2/2 - 0s - 58ms/step - loss: 0.0016 - val_loss: 3.4226e-04\n",
      "Epoch 72/100\n",
      "2/2 - 0s - 59ms/step - loss: 0.0018 - val_loss: 3.3849e-04\n",
      "Epoch 73/100\n",
      "2/2 - 0s - 56ms/step - loss: 0.0026 - val_loss: 3.3997e-04\n",
      "Epoch 74/100\n",
      "2/2 - 0s - 56ms/step - loss: 0.0016 - val_loss: 3.4573e-04\n",
      "Epoch 75/100\n",
      "2/2 - 0s - 59ms/step - loss: 0.0014 - val_loss: 4.7290e-04\n",
      "Epoch 76/100\n",
      "2/2 - 0s - 56ms/step - loss: 0.0018 - val_loss: 3.6227e-04\n",
      "Epoch 77/100\n",
      "2/2 - 0s - 57ms/step - loss: 0.0015 - val_loss: 4.0743e-04\n",
      "Epoch 78/100\n",
      "2/2 - 0s - 56ms/step - loss: 0.0018 - val_loss: 4.3389e-04\n",
      "Epoch 79/100\n",
      "2/2 - 0s - 56ms/step - loss: 0.0015 - val_loss: 3.7343e-04\n",
      "Epoch 80/100\n",
      "2/2 - 0s - 55ms/step - loss: 0.0015 - val_loss: 5.6053e-04\n",
      "Epoch 81/100\n",
      "2/2 - 0s - 55ms/step - loss: 0.0016 - val_loss: 3.5858e-04\n",
      "Epoch 82/100\n",
      "2/2 - 0s - 57ms/step - loss: 0.0015 - val_loss: 3.3937e-04\n",
      "Epoch 83/100\n",
      "2/2 - 0s - 57ms/step - loss: 0.0014 - val_loss: 4.6322e-04\n",
      "Epoch 84/100\n",
      "2/2 - 0s - 58ms/step - loss: 0.0015 - val_loss: 3.3237e-04\n",
      "Epoch 85/100\n",
      "2/2 - 0s - 57ms/step - loss: 0.0014 - val_loss: 3.5773e-04\n",
      "Epoch 86/100\n",
      "2/2 - 0s - 57ms/step - loss: 0.0018 - val_loss: 3.3866e-04\n",
      "Epoch 87/100\n",
      "2/2 - 0s - 57ms/step - loss: 0.0018 - val_loss: 3.2878e-04\n",
      "Epoch 88/100\n",
      "2/2 - 0s - 55ms/step - loss: 0.0028 - val_loss: 3.3310e-04\n",
      "Epoch 89/100\n",
      "2/2 - 0s - 55ms/step - loss: 0.0025 - val_loss: 3.7393e-04\n",
      "Epoch 90/100\n",
      "2/2 - 0s - 57ms/step - loss: 0.0015 - val_loss: 4.5040e-04\n",
      "Epoch 91/100\n",
      "2/2 - 0s - 77ms/step - loss: 0.0029 - val_loss: 3.7096e-04\n",
      "Epoch 92/100\n",
      "2/2 - 0s - 63ms/step - loss: 0.0028 - val_loss: 3.9367e-04\n",
      "Epoch 93/100\n",
      "2/2 - 0s - 58ms/step - loss: 0.0015 - val_loss: 6.3948e-04\n",
      "Epoch 94/100\n",
      "2/2 - 0s - 58ms/step - loss: 0.0019 - val_loss: 3.7933e-04\n",
      "Epoch 95/100\n",
      "2/2 - 0s - 57ms/step - loss: 0.0025 - val_loss: 3.7482e-04\n",
      "Epoch 96/100\n",
      "2/2 - 0s - 58ms/step - loss: 0.0018 - val_loss: 4.0821e-04\n",
      "Epoch 97/100\n",
      "2/2 - 0s - 58ms/step - loss: 0.0015 - val_loss: 3.7765e-04\n",
      "Epoch 98/100\n",
      "2/2 - 0s - 57ms/step - loss: 0.0014 - val_loss: 4.2870e-04\n",
      "Epoch 99/100\n",
      "2/2 - 0s - 58ms/step - loss: 0.0028 - val_loss: 4.1434e-04\n",
      "Epoch 100/100\n",
      "2/2 - 0s - 58ms/step - loss: 0.0016 - val_loss: 3.6013e-04\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step\n",
      "Model training complete and predictions made.\n"
     ]
    }
   ],
   "source": [
    "def prepare_sequences(df):\n",
    "    sequences = []\n",
    "    labels = []\n",
    "    \n",
    "    unique_ids = df['outlier_id'].unique()\n",
    "    \n",
    "    for oid in unique_ids:\n",
    "        prior_data = df[(df['outlier_id'] == oid) & (df['day type'] == 'prior day')]['c'].values\n",
    "        post_data = df[(df['outlier_id'] == oid) & (df['day type'] == 'post day')]['c'].values\n",
    "        \n",
    "        if len(prior_data) == 72 and len(post_data) >= 72:  # Ensure full sequences\n",
    "            sequences.append(prior_data)\n",
    "            labels.append(post_data[:72])  # Only the first 3 post days are needed\n",
    "            \n",
    "    return np.array(sequences), np.array(labels)\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv('USDCHF_hourly.csv')  # Make sure to load your actual data file\n",
    "\n",
    "# Clean the data - Handle missing values.\n",
    "df.drop(columns= ['prev_close', 'returns', 'day'], inplace=True)\n",
    "df.fillna(method='ffill', inplace=True)\n",
    "df.fillna(method='bfill', inplace=True)\n",
    "\n",
    "# Normalize each sequence\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "df['c'] = scaler.fit_transform(df[['c']])\n",
    "\n",
    "X, y = prepare_sequences(df)\n",
    "\n",
    "# Reshape for LSTM input\n",
    "X = X.reshape((X.shape[0], X.shape[1], 1))\n",
    "y = y.reshape((y.shape[0], 72))  # Predicting only the first 3 days of post day\n",
    "\n",
    "# Define the LSTM model\n",
    "model = Sequential([\n",
    "    LSTM(50, return_sequences=True, input_shape=(72, 1)),  # Input sequences are 72 time steps\n",
    "    LSTM(50),\n",
    "    Dense(72)  # Output 3 predictions\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.01), loss='mean_squared_error')\n",
    "\n",
    "# Split data into train and test sets\n",
    "train_size = int(len(X) * 0.67)\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, batch_size=64, verbose=2)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Optionally, scale back the predictions to the original scale\n",
    "predictions = scaler.inverse_transform(predictions)\n",
    "y_test = scaler.inverse_transform(y_test)\n",
    "\n",
    "print(\"Model training complete and predictions made.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 3.9944456553572673e-05\n",
      "Mean Absolute Error: 0.004812387739706601\n",
      "Root Mean Squared Error: 0.006320162699928909\n",
      "R-squared: 0.960058741414035\n"
     ]
    }
   ],
   "source": [
    "# Calculate MSE and MAE\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "mae = mean_absolute_error(y_test, predictions)\n",
    "rmse = np.sqrt(mse)  # Calculate RMSE\n",
    "r2 = r2_score(y_test, predictions)  # Calculate R^2 score\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"Mean Absolute Error: {mae}\")\n",
    "print(f\"Root Mean Squared Error: {rmse}\")\n",
    "print(f\"R-squared: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Function to prepare sequences for training\n",
    "def prepare_sequences_train(df):\n",
    "    sequences = []\n",
    "    labels = []\n",
    "    \n",
    "    unique_ids = df['outlier_id'].unique()\n",
    "    \n",
    "    for oid in unique_ids:\n",
    "        prior_data = df[(df['outlier_id'] == oid) & (df['day type'] == 'prior day')]['c'].values\n",
    "        post_data = df[(df['outlier_id'] == oid) & (df['day type'] == 'post day')]['c'].values\n",
    "        \n",
    "        if len(prior_data) == 72 and len(post_data) >= 72:\n",
    "            sequences.append(prior_data)\n",
    "            labels.append(post_data[:72])\n",
    "        else:\n",
    "            print(f\"Skipping outlier_id {oid} due to insufficient prior or post data\")\n",
    "    return np.array(sequences), np.array(labels)\n",
    "\n",
    "# Load and prepare training data\n",
    "def train_model(file_path):\n",
    "    df_train = pd.read_csv(file_path) # Augmented Data csv file\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    df_train['c'] = scaler.fit_transform(df_train[['c']])\n",
    "    \n",
    "    X_train, y_train = prepare_sequences_train(df_train)\n",
    "    X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "    y_train = y_train.reshape((y_train.shape[0], 72))\n",
    "    \n",
    "    model = Sequential([\n",
    "        LSTM(50, return_sequences=True, input_shape=(72, 1)),\n",
    "        LSTM(50),\n",
    "        Dense(72)\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=0.01), loss='mean_squared_error')\n",
    "    model.fit(X_train, y_train, epochs=100, batch_size=64, verbose=2)\n",
    "    return model, scaler\n",
    "\n",
    "# Function to prepare a single sequence for prediction\n",
    "def prepare_sequence_predict(df_prior, scaler):\n",
    "    prior_data = df_prior['c'].values # \"df_prior\" should be the dataframe containing prior day's data for the current outlier.\n",
    "    prior_data = scaler.transform(prior_data.reshape(-1, 1)).flatten()\n",
    "    return prior_data.reshape(1, 72, 1)\n",
    "\n",
    "# Function to predict using the model\n",
    "def predict(model, df_prior, scaler):\n",
    "    X_test = prepare_sequence_predict(df_prior, scaler)\n",
    "    predictions = model.predict(X_test)\n",
    "    return scaler.inverse_transform(predictions.reshape(-1, 1))\n",
    "\n",
    "# Function to validate predictions\n",
    "def validate_predictions(predictions, df_post, scaler):\n",
    "    post_data = df_post['c'].values[:72] # \"df_post\" should be the dataframe containing post day's data for the current outlier.\n",
    "    post_data_scaled = scaler.transform(post_data.reshape(-1, 1)).flatten()\n",
    "    \n",
    "    mse = mean_squared_error(post_data_scaled, predictions.flatten())\n",
    "    mae = mean_absolute_error(post_data_scaled, predictions.flatten())\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(post_data_scaled, predictions.flatten())\n",
    "\n",
    "    print(f\"Mean Squared Error: {mse}\")\n",
    "    print(f\"Mean Absolute Error: {mae}\")\n",
    "    print(f\"Root Mean Squared Error: {rmse}\")\n",
    "    print(f\"R-squared: {r2}\")\n",
    "\n",
    "# Example usage:\n",
    "model, scaler = train_model('train_data.csv')\n",
    "predictions = predict(model, df_prior, scaler)\n",
    "validate_predictions(predictions, df_post, scaler)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
