{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.tseries.offsets import BDay\n",
    "import requests\n",
    "from datetime import timedelta\n",
    "from scipy.stats import pearsonr\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_percentage_error, mean_absolute_error, mean_squared_error, r2_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying Outliers in last 12 months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_data(url):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code != 200:\n",
    "        print(\"Error fetching data:\", response.status_code, response.text)\n",
    "        return None\n",
    "    data = response.json()\n",
    "    if 'results' not in data:\n",
    "        print(\"No 'results' key in response:\", data)\n",
    "        return None\n",
    "    return data\n",
    "\n",
    "def calculate_daily_returns(df, prev_close=None):\n",
    "    if prev_close is not None:\n",
    "        df.loc[df.index[0], 'prev_close'] = prev_close\n",
    "    else:\n",
    "        df['prev_close'] = df['c'].shift(1)\n",
    "    df['daily_return'] = (df['c'] - df['prev_close']) / df['prev_close']\n",
    "    df['abs_daily_return'] = df['daily_return'].abs()\n",
    "    return df\n",
    "\n",
    "def get_top_outliers(df, n=10):\n",
    "    return df.nlargest(n, 'abs_daily_return')\n",
    "\n",
    "def update_outliers_list(current_df, historical_outliers_df, real_time_outliers_df, n=10):\n",
    "    if 'source' not in current_df.columns:\n",
    "        current_df['source'] = 'real-time'\n",
    "    combined_df = pd.concat([historical_outliers_df, current_df])\n",
    "    updated_outliers_df = combined_df.nlargest(n, 'abs_daily_return')\n",
    "    updated_historical_outliers_df = updated_outliers_df[updated_outliers_df['source'] == 'historical']\n",
    "    updated_real_time_outliers_df = updated_outliers_df[updated_outliers_df['source'] == 'real-time']\n",
    "    return updated_historical_outliers_df, updated_real_time_outliers_df\n",
    "\n",
    "def convert_timestamps(df):\n",
    "    df['date'] = pd.to_datetime(df['t'], unit='ms')\n",
    "    df.drop(columns=['t'], inplace=True)\n",
    "    return df\n",
    "\n",
    "# API key and endpoints\n",
    "api_key = 'beBybSi8daPgsTp5yx5cHtHpYcrjp5Jq'\n",
    "today = pd.Timestamp.now().date()\n",
    "start_date = today - pd.DateOffset(years=1)\n",
    "start_date_formatted = start_date.strftime('%Y-%m-%d')\n",
    "end_date = today - pd.DateOffset(days=1)\n",
    "end_date_formatted = end_date.strftime('%Y-%m-%d')\n",
    "symbol = 'C:USDCHF'\n",
    "historical_url = f'https://api.polygon.io/v2/aggs/ticker/{symbol}/range/1/day/{start_date_formatted}/{end_date_formatted}?adjusted=true&sort=asc&apiKey={api_key}'\n",
    "real_time_url = f'https://api.polygon.io/v2/aggs/ticker/{symbol}/range/1/day/{today}/{today}?adjusted=true&sort=asc&apiKey={api_key}'\n",
    "\n",
    "# Fetch and process historical data\n",
    "historical_data = fetch_data(historical_url)\n",
    "if historical_data:\n",
    "    historical_df = pd.DataFrame(historical_data['results'])\n",
    "    historical_df = convert_timestamps(historical_df)\n",
    "    historical_df = calculate_daily_returns(historical_df)\n",
    "    historical_df['source'] = 'historical'\n",
    "    historical_outliers_df = get_top_outliers(historical_df)\n",
    "else:\n",
    "    print(\"Failed to fetch or process historical data.\")\n",
    "\n",
    "# Fetch and process real-time data\n",
    "real_time_data = fetch_data(real_time_url)\n",
    "if real_time_data and 'results' in real_time_data:\n",
    "    real_time_df = pd.DataFrame(real_time_data['results'])\n",
    "    real_time_df = convert_timestamps(real_time_df)\n",
    "    # Use the last close from historical data\n",
    "    last_close = historical_df['c'].iloc[-1] if not historical_df.empty else None\n",
    "    real_time_df = calculate_daily_returns(real_time_df, prev_close=last_close)\n",
    "    real_time_df['source'] = 'real-time'\n",
    "    updated_historical_outliers_df, updated_real_time_outliers_df = update_outliers_list(real_time_df, historical_outliers_df, pd.DataFrame())\n",
    "    # Update historical data\n",
    "    historical_df = pd.concat([historical_df.iloc[1:], real_time_df])  # Keep historical data rolling\n",
    "else:\n",
    "    print(\"No new data available or failed to fetch real-time data.\")\n",
    "    \n",
    "# Combine data for Top 10 Outliers\n",
    "full_outlier_df = pd.concat([updated_historical_outliers_df, updated_real_time_outliers_df])\n",
    "\n",
    "# Print the Outliers\n",
    "full_outlier_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_outliers_data = full_outlier_df.sort_values(by=\"date\")\n",
    "sorted_outliers_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetching Hourly data for 3 days prior and post outlier days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dates in dataset to datetime objects\n",
    "sorted_outliers_data['date'] = pd.to_datetime(sorted_outliers_data['date'])\n",
    "\n",
    "date_ranges = pd.DataFrame({\n",
    "    \"start_date\": sorted_outliers_data['date'] - BDay(10), # To predict X days, keep this as X-1 (as 1 day of outlier will be considered in LSTM input)\n",
    "    \"end_date\": sorted_outliers_data['date'] + BDay(11),\n",
    "    \"outlier_date\": sorted_outliers_data['date'],\n",
    "})\n",
    "\n",
    "date_ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_daily_returns(df, prev_close=None):\n",
    "    if prev_close is not None:\n",
    "        df.loc[df.index[0], 'prev_close'] = prev_close\n",
    "    else:\n",
    "        df['prev_close'] = df['c'].shift(1)\n",
    "    df['returns'] = (df['c'] - df['prev_close']) / df['prev_close']\n",
    "    return df\n",
    "\n",
    "def fetch_hourly_data_chunk(symbol, start_date, end_date, api_key):\n",
    "    formatted_start_date = start_date.strftime('%Y-%m-%d')\n",
    "    formatted_end_date = end_date.strftime('%Y-%m-%d')\n",
    "\n",
    "    url = f\"https://api.polygon.io/v2/aggs/ticker/{symbol}/range/1/hour/{formatted_start_date}/{formatted_end_date}?apiKey={api_key}\"\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        print(f\"Failed to fetch data: {response.status_code} - {response.text}\")\n",
    "        return None\n",
    "    \n",
    "    response_data = response.json()\n",
    "    \n",
    "    if 'results' not in response_data:\n",
    "        print(f\"No 'results' in response: {response_data}\")\n",
    "        return None\n",
    "\n",
    "    df = pd.DataFrame(response_data['results'])\n",
    "    df['date'] = pd.to_datetime(df['t'], unit='ms')\n",
    "    df.drop(columns=['t'], inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def fetch_and_process_hourly_data(symbol, start_date, end_date, api_key):\n",
    "    pd.set_option('display.max_rows', None)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.max_colwidth', None)\n",
    "    \n",
    "    # Split the date range into smaller chunks\n",
    "    chunk_size = 3  # Fetch data in 7-day chunks\n",
    "    date_ranges = [(start_date + timedelta(days=i*chunk_size), \n",
    "                    min(end_date, start_date + timedelta(days=(i+1)*chunk_size - 1)))\n",
    "                   for i in range((end_date - start_date).days // chunk_size + 1)]\n",
    "\n",
    "    # print((end_date - start_date).days // chunk_size + 1)\n",
    "    all_data = []\n",
    "\n",
    "    for start, end in date_ranges:\n",
    "        chunk_data = fetch_hourly_data_chunk(symbol, start, end, api_key)\n",
    "        if chunk_data is not None:\n",
    "            all_data.append(chunk_data)\n",
    "    \n",
    "    if not all_data:\n",
    "        print(\"No data fetched\")\n",
    "        return None\n",
    "    \n",
    "    df = pd.concat(all_data)\n",
    "    hourly_data = calculate_daily_returns(df)\n",
    "    hourly_data.set_index('date', inplace=True)\n",
    "    \n",
    "    full_index = pd.date_range(start=start_date, end=end_date + timedelta(days=1), freq='H')\n",
    "    hourly_data = hourly_data.reindex(full_index)\n",
    "    \n",
    "    hourly_data.reset_index(inplace=True)\n",
    "    hourly_data.rename(columns={'index': 'date'}, inplace=True)\n",
    "    \n",
    "    return hourly_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictive Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetching 3 days prior and post data for the latest outlier for vailidating predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialize an outlier identifier starting from 1 or any specific number\n",
    "outlier_id = 1\n",
    "\n",
    "# Convert start_date, end_date, and outlier_date to Timestamp for consistent comparison\n",
    "start_date_co = pd.Timestamp(date_ranges['start_date'].iloc[-1])\n",
    "end_date_co = pd.Timestamp(date_ranges['end_date'].iloc[-1]) + pd.Timedelta(days=1)  # Extend the end date by one additional day\n",
    "outlier_date_co = pd.Timestamp(date_ranges['outlier_date'].iloc[-1])\n",
    "\n",
    "# Get hourly data for the range including 3 days before and after the outlier\n",
    "hourly_data = fetch_and_process_hourly_data(symbol, start_date_co, end_date_co, api_key)\n",
    "\n",
    "# Assign the current outlier_id to the data\n",
    "hourly_data['outlier_id'] = outlier_id\n",
    "\n",
    "# Filter out weekdends\n",
    "hourly_data = hourly_data[~hourly_data['date'].dt.weekday.isin([5,6])]\n",
    "\n",
    "# prior_data from start_date to outlier_date inclusive\n",
    "df_prior = hourly_data[(hourly_data['date'] >= start_date_co) & (hourly_data['date'] < outlier_date_co)]\n",
    "df_prior[\"day type\"] = \"prior day\"\n",
    "\n",
    "# outlier_data is for the hourly data on the day of the outlier\n",
    "df_outlier = hourly_data[(hourly_data['date'].dt.date == outlier_date_co.date())]\n",
    "df_outlier[\"day type\"] = \"outlier day\"\n",
    "\n",
    "# post_data from the day after outlier_date to end_date\n",
    "post_outlier_co = outlier_date_co + pd.Timedelta(days=1)  # Starting the day after the outlier_date\n",
    "df_post = hourly_data[(hourly_data['date'] >= post_outlier_co) & (hourly_data['date'] < end_date_co)]\n",
    "df_post[\"day type\"] = \"post day\"\n",
    "\n",
    "new_df = pd.concat([df_prior, df_outlier, df_post], axis=0)\n",
    "\n",
    "new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_df = new_df.sort_values(by='date', ascending=True)\n",
    "sorted_df.fillna(method='bfill', inplace=True)\n",
    "sorted_df.fillna(method='ffill', inplace=True)\n",
    "\n",
    "sorted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset\n",
    "train_set = sorted_df.iloc[:264].reset_index(drop=True) # Change iloc positions for 10 days prediction, use \":10\"\n",
    "test_set = sorted_df.iloc[264:].reset_index(drop=True) # Change iloc positions for 10 days prediction, use \"10:\"\n",
    "\n",
    "# Reset index if needed\n",
    "train_set = train_set.reset_index(drop=True)\n",
    "test_set = test_set.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 240  # Example sequence length for LSTM model - 10 daily value days - 10 sequence length\n",
    "\n",
    "# Filter data for the single outlier_id\n",
    "outlier_id = train_set[\"outlier_id\"].unique()[0]\n",
    "train_df = train_set[train_set[\"outlier_id\"] == outlier_id].set_index(\"date\")\n",
    "train_df.index = pd.to_datetime(train_df.index)  # Convert index to DateTimeIndex\n",
    "test_df = test_set[test_set[\"outlier_id\"] == outlier_id]\n",
    "\n",
    "# Normalize data\n",
    "scaler = MinMaxScaler()\n",
    "train_scaled = scaler.fit_transform(train_df[[\"c\"]])\n",
    "\n",
    "# Prepare data for LSTM model\n",
    "train_generator = TimeseriesGenerator(train_scaled, train_scaled, length=sequence_length, batch_size=1)\n",
    "\n",
    "# Define and compile LSTM model\n",
    "model = Sequential([\n",
    "    LSTM(64, activation='relu', input_shape=(sequence_length, 1)),\n",
    "    Dense(1)\n",
    "])\n",
    "model.compile(optimizer=Adam(learning_rate=0.01), loss='mean_squared_error')\n",
    "\n",
    "# Fit the model\n",
    "model.fit(train_generator, epochs=100, verbose=0)\n",
    "\n",
    "# Prepare last sequence for forecasting\n",
    "last_sequence = train_scaled[-sequence_length:]\n",
    "\n",
    "# Iteratively forecast the next 240 steps - 10 daily value days - 10 sequence length\n",
    "forecast_steps = 240\n",
    "predictions_scaled = []\n",
    "for _ in range(forecast_steps):\n",
    "    # Reshape the last sequence for prediction\n",
    "    last_sequence_reshaped = last_sequence.reshape((1, sequence_length, 1))\n",
    "    # Predict the next step and append to predictions\n",
    "    next_step_pred = model.predict(last_sequence_reshaped, verbose=0)\n",
    "    predictions_scaled.append(next_step_pred.ravel()[0])\n",
    "    # Update the last sequence with the prediction\n",
    "    last_sequence = np.roll(last_sequence, -1)\n",
    "    last_sequence[-1] = next_step_pred\n",
    "\n",
    "# Inverse transform predictions\n",
    "predictions_inv = scaler.inverse_transform(np.array(predictions_scaled).reshape(-1, 1))\n",
    "\n",
    "# Compute metrics for the single outlier_id\n",
    "actuals = test_df[\"c\"].values[:forecast_steps]\n",
    "\n",
    "mse = mean_squared_error(actuals, predictions_inv)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(actuals, predictions_inv)\n",
    "mape = mean_absolute_percentage_error(actuals, predictions_inv)\n",
    "r2 = r2_score(actuals, predictions_inv)\n",
    "\n",
    "# Calculate sMAPE\n",
    "smape = np.mean(2 * np.abs(predictions_inv - actuals) / (np.abs(predictions_inv) + np.abs(actuals))) * 100\n",
    "\n",
    "# Print metrics\n",
    "print(\"MAE:\", mae)\n",
    "print(\"MSE:\", mse)\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"MAPE:\", mape)\n",
    "print(\"sMAPE:\", smape)\n",
    "print(\"R^2:\", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 step prediction - 3 hours\n",
    "1. RMSE: 0.0014249278565365072\n",
    "2. MAE: 0.0013819148000081178\n",
    "3. MAPE: 0.0016188677009796257\n",
    "4. sMAPE: 0.16202621303027964\n",
    "5. R^2: -152.04668816591115\n",
    "\n",
    "#### 24 steps predictions - 24 hours - 1 day\n",
    "1. RMSE: 0.0034528471986093857\n",
    "2. MAE: 0.0031602989514668786\n",
    "3. MAPE: 0.0037021375133191553\n",
    "4. sMAPE: 0.38530215208360313\n",
    "5. R^2: -3.3388885069594343\n",
    "\n",
    "#### 216 steps - 9 days\n",
    "1. MAE: 0.003084491074504933\n",
    "2. MSE: 1.2475740906942047e-05\n",
    "3. RMSE: 0.0035321014859346902\n",
    "4. MAPE: 0.0036341938240416825\n",
    "5. sMAPE: 0.4224267720020953\n",
    "6. R^2: 0.11754503942796934\n",
    "\n",
    "#### 240 steps - 10 days\n",
    "1. MAE: 0.002961868462021624\n",
    "2. MSE: 1.2733241896113776e-05\n",
    "3. RMSE: 0.003568366838781262\n",
    "4. MAPE: 0.0034965434280448044\n",
    "5. sMAPE: 0.36766986776281707\n",
    "6. R^2: 0.07253019544913986\n",
    "\n",
    "#### 336 steps - 14 days\n",
    "1. MAE: 0.009938953848609888\n",
    "2. MSE: 0.00013717247923436177\n",
    "3. RMSE: 0.011712065540901049\n",
    "4. MAPE: 0.011490952565699\n",
    "5. PE: 1.1586982793510603\n",
    "6. R^2: -2.244672531975713"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eval Params for Time Series Forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In time series forecasting, the following evaluation metrics are commonly used to assess model performance:\n",
    "\n",
    "1. **Mean Absolute Error (MAE):**\n",
    "   - Measures the average magnitude of the errors between predicted and actual values, regardless of direction.\n",
    "   - Formula: \n",
    "\t \n",
    "     $\\text{MAE} = \\frac{1}{n} \\sum_{i=1}^{n} \\left| y_i - \\hat{y}_i \\right|$\n",
    "\n",
    "   - **Pros:** Easy to interpret.\n",
    "   - **Cons:** Treats all errors equally, without penalizing larger errors more.\n",
    "\n",
    "\n",
    "2. **Mean Squared Error (MSE):**\n",
    "   - Measures the average of the squared errors, which penalizes larger errors more heavily.\n",
    "   - Formula: \n",
    "\n",
    "     $\\text{MSE} = \\frac{1}{n} \\sum_{i=1}^{n} \\left( y_i - \\hat{y}_i \\right)^2$\n",
    "\n",
    "   - **Pros:** Highlights larger errors due to squaring, which can be useful if large deviations are particularly undesirable.\n",
    "   - **Cons:** Can be sensitive to outliers.\n",
    "\n",
    "3. **Root Mean Squared Error (RMSE):**\n",
    "   - The square root of MSE, bringing the error metric back to the original scale of the data.\n",
    "   - Formula: \n",
    "\n",
    "     $\\text{RMSE} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} \\left( y_i - \\hat{y}_i \\right)^2}$\n",
    "\n",
    "   - **Pros:** More interpretable than MSE due to being on the same scale as the data.\n",
    "   - **Cons:** Still sensitive to outliers.\n",
    "\n",
    "4. **Mean Absolute Percentage Error (MAPE):**\n",
    "   - Measures the average percentage error between the forecasted and actual values.\n",
    "   - Formula: \n",
    "\n",
    "     $\\text{MAPE} = \\frac{100}{n} \\sum_{i=1}^{n} \\left| \\frac{y_i - \\hat{y}_i}{y_i} \\right|$\n",
    "\n",
    "   - **Pros:** Expresses errors as a percentage, which can be easier to interpret across different datasets.\n",
    "   - **Cons:** Can be misleading if actual values are close to zero, leading to high error rates.\n",
    "\n",
    "5. **Symmetric Mean Absolute Percentage Error (sMAPE):**\n",
    "   - A variation of MAPE that addresses its sensitivity to extreme values.\n",
    "   - Formula: \n",
    "\n",
    "     $\\text{sMAPE} = \\frac{100}{n} \\sum_{i=1}^{n} \\frac{\\left| y_i - \\hat{y}_i \\right|}{\\left( |y_i| + |\\hat{y}_i| \\right) / 2}$\n",
    "\n",
    "   - **Pros:** Less sensitive to large percentage errors.\n",
    "   - **Cons:** More complex to interpret.\n",
    "\n",
    "6. **R-squared (Coefficient of Determination):**\n",
    "   - Measures the proportion of the variance in the dependent variable that is predictable from the independent variables.\n",
    "   - Formula:\n",
    "\n",
    "     $R^2 = 1 - \\frac{\\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2}{\\sum_{i=1}^{n} (y_i - \\bar{y})^2}$\n",
    "\n",
    "   - **Pros:** Indicates the goodness-of-fit.\n",
    "   - **Cons:** Not always informative for time series data, as it assumes independence between observations.\n",
    "\n",
    "7. **Mean Absolute Scaled Error (MASE):**\n",
    "   - Compares the forecasting modelâ€™s performance to a naÃ¯ve forecast (e.g., last observed value).\n",
    "   - Formula: \n",
    "\n",
    "     $\\text{MASE} = \\frac{\\text{MAE}}{\\text{MAE of naÃ¯ve forecast}}$\n",
    "\n",
    "   - **Pros:** Useful for comparing models across different datasets.\n",
    "   - **Cons:** Requires a good benchmark model for comparison.\n",
    "\n",
    "In our case of predicting close prices, MAE, RMSE, and MASE are typically the most relevant because they directly measure the error magnitude in the same units as the data, making them more interpretable for financial time series."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eval Params for Financial Market"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to the standard metrics, the following metrics can provide deeper insights into the performance of our time series forecasting model in the forex market:\n",
    "\n",
    "1. **Directional Accuracy (DA):**\n",
    "   - Measures how often the model correctly predicts the direction of price movement (up or down).\n",
    "   - Formula:\n",
    "\n",
    "     $\\text{DA} = \\frac{1}{n} \\sum_{i=1}^{n} \\mathbb{1}\\left[\\text{sign}(\\hat{y}_i - y_{i-1}) = \\text{sign}(y_i - y_{i-1})\\right]$\n",
    "\n",
    "   - **Pros:** Directly relevant for trading strategies, as correct direction prediction is often more critical than exact value prediction.\n",
    "   - **Cons:** Does not account for the magnitude of the forecast error.\n",
    "\n",
    "2. **Profit and Loss (P&L):**\n",
    "   - Evaluates the hypothetical profit or loss if a trading strategy based on the model's predictions was implemented.\n",
    "   - **Pros:** Provides practical insights into how well the model would perform in real trading scenarios.\n",
    "   - **Cons:** Requires a well-defined trading strategy to simulate P&L.\n",
    "\n",
    "3. **Hit Rate (HR):**\n",
    "   - Measures the percentage of times the model's predicted direction and the actual market direction match.\n",
    "   - **Pros:** Useful for understanding how often the model makes correct directional calls.\n",
    "   - **Cons:** Does not quantify the magnitude of errors when the direction is incorrect.\n",
    "\n",
    "4. **Maximum Drawdown (MDD):**\n",
    "   - Measures the largest peak-to-trough decline in a simulated trading equity curve using the model's predictions.\n",
    "   - **Pros:** Helps assess the risk of the model in terms of potential losses.\n",
    "   - **Cons:** Requires simulation over a trading strategy to calculate.\n",
    "\n",
    "5. **Sharpe Ratio:**\n",
    "   - Evaluates the risk-adjusted return of a trading strategy based on the model's predictions.\n",
    "   - Formula:\n",
    "\n",
    "     \\text{Sharpe Ratio} = \\frac{\\text{Average P\\&L} - \\text{Risk-Free Rate}}{\\text{Standard Deviation of P\\&L}}\n",
    "\n",
    "   - **Pros:** Balances returns with the associated risk, offering a comprehensive measure of strategy performance.\n",
    "   - **Cons:** Assumes returns are normally distributed, which might not always hold in financial markets.\n",
    "\n",
    "6. **Mean Directional Accuracy (MDA):**\n",
    "   - Similar to directional accuracy but gives a more refined measure by focusing on the average accuracy of the directional predictions.\n",
    "   - Formula:\n",
    "\n",
    "     \\text{MDA} = \\frac{1}{n} \\sum_{i=1}^{n} \\frac{\\mathbb{1}\\left[\\text{sign}(\\hat{y}_i - y_{i-1}) = \\text{sign}(y_i - y_{i-1})\\right]}{n}\n",
    "\n",
    "   - **Pros:** Useful when focusing on directionality rather than magnitude.\n",
    "   - **Cons:** Overlooks large errors in magnitude.\n",
    "\n",
    "7. **Volatility Adjusted Return (VAR):**\n",
    "   - Measures return adjusted for volatility to understand how the model performs under varying market conditions.\n",
    "   - **Pros:** Important in markets like forex, where volatility can significantly impact performance.\n",
    "   - **Cons:** Requires more complex calculation and an understanding of market volatility.\n",
    "\n",
    "8. **Value at Risk (VaR):**\n",
    "   - Estimates the potential loss in value of a portfolio over a defined period for a given confidence interval.\n",
    "   - **Pros:** Helps assess the potential downside risk.\n",
    "   - **Cons:** Does not account for losses beyond the confidence interval threshold.\n",
    "\n",
    "Using these metrics in combination with the standard error metrics can give us a more comprehensive understanding of how our model might perform in real-world trading scenarios, particularly in the highly volatile forex market."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
