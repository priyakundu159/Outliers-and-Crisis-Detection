{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, TimeDistributed, Lambda\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vw</th>\n",
       "      <th>o</th>\n",
       "      <th>c</th>\n",
       "      <th>h</th>\n",
       "      <th>l</th>\n",
       "      <th>n</th>\n",
       "      <th>prev_close</th>\n",
       "      <th>daily_return</th>\n",
       "      <th>abs_daily_return</th>\n",
       "      <th>pct_change</th>\n",
       "      <th>direction</th>\n",
       "      <th>recovery</th>\n",
       "      <th>outlier_id</th>\n",
       "      <th>day type</th>\n",
       "      <th>day</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.1342</td>\n",
       "      <td>1.13310</td>\n",
       "      <td>1.13420</td>\n",
       "      <td>1.13550</td>\n",
       "      <td>1.13256</td>\n",
       "      <td>5562.0</td>\n",
       "      <td>1.13310</td>\n",
       "      <td>0.000971</td>\n",
       "      <td>0.000971</td>\n",
       "      <td>0.097079</td>\n",
       "      <td>Up</td>\n",
       "      <td>fast recovery</td>\n",
       "      <td>1</td>\n",
       "      <td>prior day</td>\n",
       "      <td>Monday</td>\n",
       "      <td>2010-05-17</td>\n",
       "      <td>00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.1340</td>\n",
       "      <td>1.13420</td>\n",
       "      <td>1.13438</td>\n",
       "      <td>1.13527</td>\n",
       "      <td>1.13275</td>\n",
       "      <td>5581.0</td>\n",
       "      <td>1.13420</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.015870</td>\n",
       "      <td>Up</td>\n",
       "      <td>fast recovery</td>\n",
       "      <td>1</td>\n",
       "      <td>prior day</td>\n",
       "      <td>Monday</td>\n",
       "      <td>2010-05-17</td>\n",
       "      <td>01:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.1403</td>\n",
       "      <td>1.13440</td>\n",
       "      <td>1.14112</td>\n",
       "      <td>1.14450</td>\n",
       "      <td>1.13438</td>\n",
       "      <td>11640.0</td>\n",
       "      <td>1.13438</td>\n",
       "      <td>0.005942</td>\n",
       "      <td>0.005942</td>\n",
       "      <td>0.594157</td>\n",
       "      <td>Up</td>\n",
       "      <td>fast recovery</td>\n",
       "      <td>1</td>\n",
       "      <td>prior day</td>\n",
       "      <td>Monday</td>\n",
       "      <td>2010-05-17</td>\n",
       "      <td>02:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.1411</td>\n",
       "      <td>1.14108</td>\n",
       "      <td>1.14149</td>\n",
       "      <td>1.14284</td>\n",
       "      <td>1.13929</td>\n",
       "      <td>5978.0</td>\n",
       "      <td>1.14112</td>\n",
       "      <td>0.000324</td>\n",
       "      <td>0.000324</td>\n",
       "      <td>0.032424</td>\n",
       "      <td>Up</td>\n",
       "      <td>fast recovery</td>\n",
       "      <td>1</td>\n",
       "      <td>prior day</td>\n",
       "      <td>Monday</td>\n",
       "      <td>2010-05-17</td>\n",
       "      <td>03:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.1405</td>\n",
       "      <td>1.14149</td>\n",
       "      <td>1.13926</td>\n",
       "      <td>1.14168</td>\n",
       "      <td>1.13918</td>\n",
       "      <td>4710.0</td>\n",
       "      <td>1.14149</td>\n",
       "      <td>-0.001954</td>\n",
       "      <td>0.001954</td>\n",
       "      <td>0.195359</td>\n",
       "      <td>Down</td>\n",
       "      <td>fast recovery</td>\n",
       "      <td>1</td>\n",
       "      <td>prior day</td>\n",
       "      <td>Monday</td>\n",
       "      <td>2010-05-17</td>\n",
       "      <td>04:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38776</th>\n",
       "      <td>0.9328</td>\n",
       "      <td>0.93164</td>\n",
       "      <td>0.93330</td>\n",
       "      <td>0.93400</td>\n",
       "      <td>0.93120</td>\n",
       "      <td>7392.0</td>\n",
       "      <td>0.93164</td>\n",
       "      <td>0.001782</td>\n",
       "      <td>0.001782</td>\n",
       "      <td>0.178180</td>\n",
       "      <td>Up</td>\n",
       "      <td>slow recovery</td>\n",
       "      <td>140</td>\n",
       "      <td>post day</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>2023-03-15</td>\n",
       "      <td>20:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38777</th>\n",
       "      <td>0.9330</td>\n",
       "      <td>0.93330</td>\n",
       "      <td>0.93290</td>\n",
       "      <td>0.93340</td>\n",
       "      <td>0.93167</td>\n",
       "      <td>958.0</td>\n",
       "      <td>0.93330</td>\n",
       "      <td>-0.000429</td>\n",
       "      <td>0.000429</td>\n",
       "      <td>0.042859</td>\n",
       "      <td>Down</td>\n",
       "      <td>slow recovery</td>\n",
       "      <td>140</td>\n",
       "      <td>post day</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>2023-03-15</td>\n",
       "      <td>21:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38778</th>\n",
       "      <td>0.9328</td>\n",
       "      <td>0.93303</td>\n",
       "      <td>0.93190</td>\n",
       "      <td>0.93430</td>\n",
       "      <td>0.93150</td>\n",
       "      <td>4998.0</td>\n",
       "      <td>0.93290</td>\n",
       "      <td>-0.001072</td>\n",
       "      <td>0.001072</td>\n",
       "      <td>0.107193</td>\n",
       "      <td>Down</td>\n",
       "      <td>slow recovery</td>\n",
       "      <td>140</td>\n",
       "      <td>post day</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>2023-03-15</td>\n",
       "      <td>22:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38779</th>\n",
       "      <td>0.9313</td>\n",
       "      <td>0.93210</td>\n",
       "      <td>0.93126</td>\n",
       "      <td>0.93236</td>\n",
       "      <td>0.93070</td>\n",
       "      <td>8034.0</td>\n",
       "      <td>0.93190</td>\n",
       "      <td>-0.000687</td>\n",
       "      <td>0.000687</td>\n",
       "      <td>0.068677</td>\n",
       "      <td>Down</td>\n",
       "      <td>slow recovery</td>\n",
       "      <td>140</td>\n",
       "      <td>post day</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>2023-03-15</td>\n",
       "      <td>23:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38780</th>\n",
       "      <td>0.9304</td>\n",
       "      <td>0.93126</td>\n",
       "      <td>0.93160</td>\n",
       "      <td>0.93192</td>\n",
       "      <td>0.92950</td>\n",
       "      <td>11928.0</td>\n",
       "      <td>0.93126</td>\n",
       "      <td>0.000365</td>\n",
       "      <td>0.000365</td>\n",
       "      <td>0.036510</td>\n",
       "      <td>Up</td>\n",
       "      <td>slow recovery</td>\n",
       "      <td>140</td>\n",
       "      <td>post day</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>2023-03-16</td>\n",
       "      <td>00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38781 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           vw        o        c        h        l        n  prev_close  \\\n",
       "0      1.1342  1.13310  1.13420  1.13550  1.13256   5562.0     1.13310   \n",
       "1      1.1340  1.13420  1.13438  1.13527  1.13275   5581.0     1.13420   \n",
       "2      1.1403  1.13440  1.14112  1.14450  1.13438  11640.0     1.13438   \n",
       "3      1.1411  1.14108  1.14149  1.14284  1.13929   5978.0     1.14112   \n",
       "4      1.1405  1.14149  1.13926  1.14168  1.13918   4710.0     1.14149   \n",
       "...       ...      ...      ...      ...      ...      ...         ...   \n",
       "38776  0.9328  0.93164  0.93330  0.93400  0.93120   7392.0     0.93164   \n",
       "38777  0.9330  0.93330  0.93290  0.93340  0.93167    958.0     0.93330   \n",
       "38778  0.9328  0.93303  0.93190  0.93430  0.93150   4998.0     0.93290   \n",
       "38779  0.9313  0.93210  0.93126  0.93236  0.93070   8034.0     0.93190   \n",
       "38780  0.9304  0.93126  0.93160  0.93192  0.92950  11928.0     0.93126   \n",
       "\n",
       "       daily_return  abs_daily_return  pct_change direction       recovery  \\\n",
       "0          0.000971          0.000971    0.097079        Up  fast recovery   \n",
       "1          0.000159          0.000159    0.015870        Up  fast recovery   \n",
       "2          0.005942          0.005942    0.594157        Up  fast recovery   \n",
       "3          0.000324          0.000324    0.032424        Up  fast recovery   \n",
       "4         -0.001954          0.001954    0.195359      Down  fast recovery   \n",
       "...             ...               ...         ...       ...            ...   \n",
       "38776      0.001782          0.001782    0.178180        Up  slow recovery   \n",
       "38777     -0.000429          0.000429    0.042859      Down  slow recovery   \n",
       "38778     -0.001072          0.001072    0.107193      Down  slow recovery   \n",
       "38779     -0.000687          0.000687    0.068677      Down  slow recovery   \n",
       "38780      0.000365          0.000365    0.036510        Up  slow recovery   \n",
       "\n",
       "       outlier_id   day type        day        Date      Time  \n",
       "0               1  prior day     Monday  2010-05-17  00:00:00  \n",
       "1               1  prior day     Monday  2010-05-17  01:00:00  \n",
       "2               1  prior day     Monday  2010-05-17  02:00:00  \n",
       "3               1  prior day     Monday  2010-05-17  03:00:00  \n",
       "4               1  prior day     Monday  2010-05-17  04:00:00  \n",
       "...           ...        ...        ...         ...       ...  \n",
       "38776         140   post day  Wednesday  2023-03-15  20:00:00  \n",
       "38777         140   post day  Wednesday  2023-03-15  21:00:00  \n",
       "38778         140   post day  Wednesday  2023-03-15  22:00:00  \n",
       "38779         140   post day  Wednesday  2023-03-15  23:00:00  \n",
       "38780         140   post day   Thursday  2023-03-16  00:00:00  \n",
       "\n",
       "[38781 rows x 17 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv('new_data.csv')\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the unnecesary columns\n",
    "data.drop(columns=['Unnamed: 0', 'prev_close', 'abs_daily_return', 'year'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data\n",
    "data['direction_target'] = data['direction'].apply(lambda x: 1 if x == 'Up' else 0)\n",
    "data['recovery_target'] = data['recovery'].apply(lambda x: 1 if x == 'fast recovery' else 0)\n",
    "data.drop(columns=['direction', 'recovery'], inplace=True)\n",
    "\n",
    "# Filter the data\n",
    "input_data = data[data['day type'].isin(['prior day', 'outlier day'])]\n",
    "output_data = data[data['day type'] == 'post day']\n",
    "\n",
    "# Ensure the data is sorted by Date and Time\n",
    "input_data = input_data.sort_values(by=['outlier_id', 'Date', 'Time'])\n",
    "output_data = output_data.sort_values(by=['outlier_id', 'Date', 'Time'])\n",
    "\n",
    "feature_columns = ['c', 'daily_return', 'direction_target']\n",
    "seq_length = 24\n",
    "\n",
    "def create_sequences_per_outlier(input_data, output_data, feature_columns, seq_length=24):\n",
    "    sequences = []\n",
    "    direction_targets = []\n",
    "    recovery_targets = []\n",
    "    \n",
    "    unique_ids = input_data['outlier_id'].unique()\n",
    "    \n",
    "    for oid in unique_ids:\n",
    "        input_seq = input_data[input_data['outlier_id'] == oid]\n",
    "        output_seq = output_data[output_data['outlier_id'] == oid]\n",
    "\n",
    "        # Normalize features\n",
    "        scaler = MinMaxScaler()\n",
    "        input_features = scaler.fit_transform(input_seq[feature_columns])\n",
    "        \n",
    "        # Ensure sequence length is exactly `seq_length` for input features\n",
    "        if len(input_features) >= seq_length:\n",
    "            input_features = input_features[-120:]  # Take last `seq_length` entries\n",
    "        else:\n",
    "            # Pad input_features if they are shorter than seq_length\n",
    "            padding = np.zeros((seq_length - len(input_features), input_features.shape[1]))\n",
    "            input_features = np.vstack([padding, input_features])\n",
    "\n",
    "        # Same for output sequences\n",
    "        if len(output_seq) >= seq_length:\n",
    "            directions = output_seq['direction_target'].iloc[:seq_length].values\n",
    "        else:\n",
    "            # Padding direction and recovery targets if they are shorter than seq_length\n",
    "            directions = np.pad(output_seq['direction_target'].values, (seq_length - len(output_seq), 0), 'constant')\n",
    "\n",
    "        # Store sequences and targets as arrays\n",
    "        sequences.append(input_features)\n",
    "        direction_targets.append(directions)\n",
    "        recovery_targets.append(recoveries)\n",
    "    \n",
    "    return np.array(sequences), np.array(direction_targets)\n",
    "\n",
    "# Create sequences\n",
    "sequences, direction_targets = create_sequences_per_outlier(input_data, output_data, feature_columns, seq_length)\n",
    "\n",
    "# Convert to numpy array for model input\n",
    "X = np.array(sequences)\n",
    "\n",
    "# Split the data into training and testing sets based on outlier IDs\n",
    "outlier_ids = input_data['outlier_id'].unique()\n",
    "train_ids, test_ids = train_test_split(outlier_ids, test_size=0.3, random_state=123)\n",
    "\n",
    "# Create indices for the sequences\n",
    "train_idx = [i for i, oid in enumerate(outlier_ids) if oid in train_ids]\n",
    "test_idx = [i for i, oid in enumerate(outlier_ids) if oid in test_ids]\n",
    "\n",
    "X_train = X[train_idx]\n",
    "X_test = X[test_idx]\n",
    "y_train_dir = direction_targets[train_idx]\n",
    "y_test_dir = direction_targets[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 386ms/step - accuracy: 0.4971 - loss: 0.6932 - val_accuracy: 0.5308 - val_loss: 0.6886\n",
      "Epoch 2/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 153ms/step - accuracy: 0.5242 - loss: 0.6936 - val_accuracy: 0.5308 - val_loss: 0.6887\n",
      "Epoch 3/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 161ms/step - accuracy: 0.5329 - loss: 0.6915 - val_accuracy: 0.5337 - val_loss: 0.6903\n",
      "Epoch 4/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 156ms/step - accuracy: 0.5353 - loss: 0.6909 - val_accuracy: 0.5308 - val_loss: 0.6893\n",
      "Epoch 5/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 155ms/step - accuracy: 0.5287 - loss: 0.6935 - val_accuracy: 0.5308 - val_loss: 0.6891\n",
      "Epoch 6/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 175ms/step - accuracy: 0.5323 - loss: 0.6902 - val_accuracy: 0.5308 - val_loss: 0.6892\n",
      "Epoch 7/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - accuracy: 0.5247 - loss: 0.6908 - val_accuracy: 0.5308 - val_loss: 0.6888\n",
      "Epoch 8/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - accuracy: 0.5223 - loss: 0.6922 - val_accuracy: 0.5308 - val_loss: 0.6887\n",
      "Epoch 9/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - accuracy: 0.5289 - loss: 0.6925 - val_accuracy: 0.5308 - val_loss: 0.6889\n",
      "Epoch 10/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 133ms/step - accuracy: 0.5398 - loss: 0.6907 - val_accuracy: 0.5258 - val_loss: 0.6902\n",
      "Epoch 11/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - accuracy: 0.5304 - loss: 0.6915 - val_accuracy: 0.5228 - val_loss: 0.6906\n",
      "Epoch 12/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - accuracy: 0.5258 - loss: 0.6921 - val_accuracy: 0.5278 - val_loss: 0.6900\n",
      "Epoch 13/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.5265 - loss: 0.6903 - val_accuracy: 0.5268 - val_loss: 0.6904\n",
      "Epoch 14/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.5265 - loss: 0.6926 - val_accuracy: 0.5308 - val_loss: 0.6896\n",
      "Epoch 15/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.5290 - loss: 0.6914 - val_accuracy: 0.5308 - val_loss: 0.6887\n",
      "Epoch 16/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 121ms/step - accuracy: 0.5306 - loss: 0.6909 - val_accuracy: 0.5308 - val_loss: 0.6891\n",
      "Epoch 17/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - accuracy: 0.5327 - loss: 0.6915 - val_accuracy: 0.5347 - val_loss: 0.6901\n",
      "Epoch 18/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - accuracy: 0.5249 - loss: 0.6928 - val_accuracy: 0.5109 - val_loss: 0.6922\n",
      "Epoch 19/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - accuracy: 0.5254 - loss: 0.6917 - val_accuracy: 0.5119 - val_loss: 0.6918\n",
      "Epoch 20/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - accuracy: 0.5269 - loss: 0.6909 - val_accuracy: 0.5079 - val_loss: 0.6919\n",
      "Epoch 21/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - accuracy: 0.5309 - loss: 0.6917 - val_accuracy: 0.5188 - val_loss: 0.6916\n",
      "Epoch 22/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.5124 - loss: 0.6931 - val_accuracy: 0.5308 - val_loss: 0.6896\n",
      "Epoch 23/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 0.5249 - loss: 0.6942 - val_accuracy: 0.5308 - val_loss: 0.6892\n",
      "Epoch 24/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - accuracy: 0.5310 - loss: 0.6923 - val_accuracy: 0.5129 - val_loss: 0.6917\n",
      "Epoch 25/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - accuracy: 0.5204 - loss: 0.6916 - val_accuracy: 0.5109 - val_loss: 0.6926\n",
      "Epoch 26/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - accuracy: 0.5235 - loss: 0.6921 - val_accuracy: 0.5208 - val_loss: 0.6902\n",
      "Epoch 27/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - accuracy: 0.5399 - loss: 0.6899 - val_accuracy: 0.5308 - val_loss: 0.6891\n",
      "Epoch 28/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - accuracy: 0.5336 - loss: 0.6932 - val_accuracy: 0.5308 - val_loss: 0.6889\n",
      "Epoch 29/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.5369 - loss: 0.6925 - val_accuracy: 0.5278 - val_loss: 0.6891\n",
      "Epoch 30/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - accuracy: 0.5402 - loss: 0.6910 - val_accuracy: 0.5218 - val_loss: 0.6902\n",
      "Epoch 31/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 118ms/step - accuracy: 0.5483 - loss: 0.6903 - val_accuracy: 0.5208 - val_loss: 0.6910\n",
      "Epoch 32/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - accuracy: 0.5263 - loss: 0.6916 - val_accuracy: 0.5208 - val_loss: 0.6909\n",
      "Epoch 33/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - accuracy: 0.5322 - loss: 0.6899 - val_accuracy: 0.5278 - val_loss: 0.6898\n",
      "Epoch 34/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - accuracy: 0.5422 - loss: 0.6900 - val_accuracy: 0.5288 - val_loss: 0.6886\n",
      "Epoch 35/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step - accuracy: 0.5410 - loss: 0.6887 - val_accuracy: 0.5308 - val_loss: 0.6887\n",
      "Epoch 36/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - accuracy: 0.5334 - loss: 0.6931 - val_accuracy: 0.5288 - val_loss: 0.6886\n",
      "Epoch 37/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - accuracy: 0.5390 - loss: 0.6895 - val_accuracy: 0.5258 - val_loss: 0.6890\n",
      "Epoch 38/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - accuracy: 0.5362 - loss: 0.6863 - val_accuracy: 0.5248 - val_loss: 0.6888\n",
      "Epoch 39/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - accuracy: 0.5347 - loss: 0.6916 - val_accuracy: 0.5308 - val_loss: 0.6886\n",
      "Epoch 40/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.5397 - loss: 0.6913 - val_accuracy: 0.5308 - val_loss: 0.6886\n",
      "Epoch 41/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - accuracy: 0.5413 - loss: 0.6909 - val_accuracy: 0.5208 - val_loss: 0.6889\n",
      "Epoch 42/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - accuracy: 0.5448 - loss: 0.6886 - val_accuracy: 0.5248 - val_loss: 0.6897\n",
      "Epoch 43/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 174ms/step - accuracy: 0.5343 - loss: 0.6892 - val_accuracy: 0.5278 - val_loss: 0.6898\n",
      "Epoch 44/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - accuracy: 0.5348 - loss: 0.6895 - val_accuracy: 0.5188 - val_loss: 0.6895\n",
      "Epoch 45/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - accuracy: 0.5410 - loss: 0.6874 - val_accuracy: 0.5198 - val_loss: 0.6893\n",
      "Epoch 46/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - accuracy: 0.5346 - loss: 0.6911 - val_accuracy: 0.5228 - val_loss: 0.6914\n",
      "Epoch 47/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - accuracy: 0.5245 - loss: 0.6805 - val_accuracy: 0.5248 - val_loss: 0.6946\n",
      "Epoch 48/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - accuracy: 0.5114 - loss: 0.6950 - val_accuracy: 0.5099 - val_loss: 0.6979\n",
      "Epoch 49/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - accuracy: 0.5172 - loss: 0.6907 - val_accuracy: 0.5248 - val_loss: 0.6907\n",
      "Epoch 50/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - accuracy: 0.5291 - loss: 0.6934 - val_accuracy: 0.5298 - val_loss: 0.6898\n",
      "Epoch 51/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step - accuracy: 0.5356 - loss: 0.6914 - val_accuracy: 0.5258 - val_loss: 0.6893\n",
      "Epoch 52/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - accuracy: 0.5304 - loss: 0.6875 - val_accuracy: 0.5159 - val_loss: 0.6900\n",
      "Epoch 53/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - accuracy: 0.5323 - loss: 0.6868 - val_accuracy: 0.5109 - val_loss: 0.6906\n",
      "Epoch 54/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - accuracy: 0.5446 - loss: 0.6882 - val_accuracy: 0.5169 - val_loss: 0.6901\n",
      "Epoch 55/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - accuracy: 0.5346 - loss: 0.6884 - val_accuracy: 0.5337 - val_loss: 0.6892\n",
      "Epoch 56/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - accuracy: 0.5371 - loss: 0.6885 - val_accuracy: 0.5317 - val_loss: 0.6890\n",
      "Epoch 57/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - accuracy: 0.5392 - loss: 0.6892 - val_accuracy: 0.5327 - val_loss: 0.6887\n",
      "Epoch 58/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - accuracy: 0.5449 - loss: 0.6854 - val_accuracy: 0.5308 - val_loss: 0.6890\n",
      "Epoch 59/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - accuracy: 0.5379 - loss: 0.6892 - val_accuracy: 0.5387 - val_loss: 0.6910\n",
      "Epoch 60/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - accuracy: 0.5219 - loss: 0.6887 - val_accuracy: 0.5089 - val_loss: 0.6944\n",
      "Epoch 61/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - accuracy: 0.5148 - loss: 0.6897 - val_accuracy: 0.5218 - val_loss: 0.6923\n",
      "Epoch 62/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - accuracy: 0.5338 - loss: 0.6852 - val_accuracy: 0.5367 - val_loss: 0.6904\n",
      "Epoch 63/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - accuracy: 0.5276 - loss: 0.6896 - val_accuracy: 0.5308 - val_loss: 0.6892\n",
      "Epoch 64/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 177ms/step - accuracy: 0.5389 - loss: 0.6901 - val_accuracy: 0.5317 - val_loss: 0.6890\n",
      "Epoch 65/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 130ms/step - accuracy: 0.5396 - loss: 0.6864 - val_accuracy: 0.5298 - val_loss: 0.6890\n",
      "Epoch 66/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 126ms/step - accuracy: 0.5436 - loss: 0.6854 - val_accuracy: 0.5308 - val_loss: 0.6891\n",
      "Epoch 67/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - accuracy: 0.5391 - loss: 0.6862 - val_accuracy: 0.5308 - val_loss: 0.6893\n",
      "Epoch 68/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 132ms/step - accuracy: 0.5313 - loss: 0.6864 - val_accuracy: 0.5308 - val_loss: 0.6892\n",
      "Epoch 69/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 123ms/step - accuracy: 0.5389 - loss: 0.6815 - val_accuracy: 0.5278 - val_loss: 0.6891\n",
      "Epoch 70/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - accuracy: 0.5373 - loss: 0.6903 - val_accuracy: 0.5298 - val_loss: 0.6898\n",
      "Epoch 71/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - accuracy: 0.5419 - loss: 0.6871 - val_accuracy: 0.5278 - val_loss: 0.6896\n",
      "Epoch 72/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - accuracy: 0.5366 - loss: 0.6845 - val_accuracy: 0.5327 - val_loss: 0.6903\n",
      "Epoch 73/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - accuracy: 0.5334 - loss: 0.6858 - val_accuracy: 0.5308 - val_loss: 0.6893\n",
      "Epoch 74/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - accuracy: 0.5392 - loss: 0.6716 - val_accuracy: 0.5288 - val_loss: 0.6886\n",
      "Epoch 75/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - accuracy: 0.5328 - loss: 0.6882 - val_accuracy: 0.5347 - val_loss: 0.6889\n",
      "Epoch 76/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - accuracy: 0.5374 - loss: 0.6889 - val_accuracy: 0.5317 - val_loss: 0.6894\n",
      "Epoch 77/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - accuracy: 0.5351 - loss: 0.6847 - val_accuracy: 0.5327 - val_loss: 0.6901\n",
      "Epoch 78/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - accuracy: 0.5452 - loss: 0.6859 - val_accuracy: 0.5248 - val_loss: 0.6909\n",
      "Epoch 79/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - accuracy: 0.5383 - loss: 0.6900 - val_accuracy: 0.5228 - val_loss: 0.6917\n",
      "Epoch 80/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - accuracy: 0.5356 - loss: 0.6872 - val_accuracy: 0.5327 - val_loss: 0.6918\n",
      "Epoch 81/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - accuracy: 0.5392 - loss: 0.6831 - val_accuracy: 0.5357 - val_loss: 0.6908\n",
      "Epoch 82/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - accuracy: 0.5415 - loss: 0.6861 - val_accuracy: 0.5258 - val_loss: 0.6894\n",
      "Epoch 83/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 165ms/step - accuracy: 0.5355 - loss: 0.6884 - val_accuracy: 0.5268 - val_loss: 0.6892\n",
      "Epoch 84/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - accuracy: 0.5496 - loss: 0.6839 - val_accuracy: 0.5268 - val_loss: 0.6892\n",
      "Epoch 85/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - accuracy: 0.5509 - loss: 0.6832 - val_accuracy: 0.5268 - val_loss: 0.6897\n",
      "Epoch 86/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - accuracy: 0.5329 - loss: 0.6880 - val_accuracy: 0.5278 - val_loss: 0.6903\n",
      "Epoch 87/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - accuracy: 0.5465 - loss: 0.6822 - val_accuracy: 0.5288 - val_loss: 0.6895\n",
      "Epoch 88/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - accuracy: 0.5364 - loss: 0.6885 - val_accuracy: 0.5298 - val_loss: 0.6893\n",
      "Epoch 89/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - accuracy: 0.5387 - loss: 0.6840 - val_accuracy: 0.5308 - val_loss: 0.6894\n",
      "Epoch 90/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - accuracy: 0.5352 - loss: 0.6868 - val_accuracy: 0.5298 - val_loss: 0.6895\n",
      "Epoch 91/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - accuracy: 0.5431 - loss: 0.6806 - val_accuracy: 0.5308 - val_loss: 0.6898\n",
      "Epoch 92/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - accuracy: 0.5481 - loss: 0.6829 - val_accuracy: 0.5278 - val_loss: 0.6900\n",
      "Epoch 93/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 135ms/step - accuracy: 0.5268 - loss: 0.6891 - val_accuracy: 0.5288 - val_loss: 0.6902\n",
      "Epoch 94/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - accuracy: 0.5450 - loss: 0.6850 - val_accuracy: 0.5288 - val_loss: 0.6902\n",
      "Epoch 95/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - accuracy: 0.5387 - loss: 0.6870 - val_accuracy: 0.5317 - val_loss: 0.6903\n",
      "Epoch 96/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - accuracy: 0.5408 - loss: 0.6864 - val_accuracy: 0.5317 - val_loss: 0.6903\n",
      "Epoch 97/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - accuracy: 0.5461 - loss: 0.6870 - val_accuracy: 0.5317 - val_loss: 0.6903\n",
      "Epoch 98/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - accuracy: 0.5439 - loss: 0.6862 - val_accuracy: 0.5317 - val_loss: 0.6904\n",
      "Epoch 99/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - accuracy: 0.5417 - loss: 0.6879 - val_accuracy: 0.5317 - val_loss: 0.6904\n",
      "Epoch 100/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 131ms/step - accuracy: 0.5454 - loss: 0.6806 - val_accuracy: 0.5317 - val_loss: 0.6907\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x105ddfef0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_to_one_hot(y, num_classes):\n",
    "    return np.array([to_categorical(y_i, num_classes=num_classes) for y_i in y])\n",
    "\n",
    "# Convert target labels to one-hot encoded format\n",
    "y_train_dir_one_hot = convert_to_one_hot(y_train_dir, num_classes=2)\n",
    "y_test_dir_one_hot = convert_to_one_hot(y_test_dir, num_classes=2)\n",
    "\n",
    "def slice_last_timesteps(x):\n",
    "    return x[:, :24, :]\n",
    "\n",
    "# Define the LSTM model for direction prediction with fixed 24 time step outputs\n",
    "model_direction = Sequential()\n",
    "model_direction.add(LSTM(100, return_sequences=True, input_shape=(None, X_train.shape[-1])))  # Input shape matches features count\n",
    "model_direction.add(Dropout(0.3))\n",
    "model_direction.add(LSTM(100, return_sequences=True))\n",
    "model_direction.add(Dropout(0.3))\n",
    "model_direction.add(Lambda(slice_last_timesteps))  # Slice the first 24 time steps\n",
    "model_direction.add(TimeDistributed(Dense(2, activation='softmax')))\n",
    "\n",
    "# Compile the model\n",
    "model_direction.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model_direction.fit(X_train, y_train_dir_one_hot, epochs=100, batch_size=32, validation_data=(X_test, y_test_dir_one_hot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 316ms/step\n",
      "Accuracy: 0.5317\n",
      "Precision: 0.5051\n",
      "Recall: 0.1057\n",
      "F1 Score: 0.1748\n"
     ]
    }
   ],
   "source": [
    "# 1. Make predictions on the test set\n",
    "y_test_pred_prob = model_direction.predict(X_test)\n",
    "\n",
    "# 2. Convert predictions and true labels from one-hot to class labels\n",
    "y_test_pred = np.argmax(y_test_pred_prob, axis=-1)\n",
    "y_test_true = np.argmax(y_test_dir_one_hot, axis=-1)\n",
    "\n",
    "# Flatten arrays to make them 1D for metric calculations\n",
    "y_test_pred_flat = y_test_pred.flatten()\n",
    "y_test_true_flat = y_test_true.flatten()\n",
    "\n",
    "# 3. Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_test_true_flat, y_test_pred_flat)\n",
    "precision = precision_score(y_test_true_flat, y_test_pred_flat)\n",
    "recall = recall_score(y_test_true_flat, y_test_pred_flat)\n",
    "f1 = f1_score(y_test_true_flat, y_test_pred_flat)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
