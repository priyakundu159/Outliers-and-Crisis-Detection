{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pywt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, TimeDistributed, Reshape, Lambda\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>vw</th>\n",
       "      <th>o</th>\n",
       "      <th>c</th>\n",
       "      <th>h</th>\n",
       "      <th>l</th>\n",
       "      <th>n</th>\n",
       "      <th>prev_close</th>\n",
       "      <th>daily_return</th>\n",
       "      <th>abs_daily_return</th>\n",
       "      <th>pct_change</th>\n",
       "      <th>direction</th>\n",
       "      <th>Recovery</th>\n",
       "      <th>outlier_id</th>\n",
       "      <th>day type</th>\n",
       "      <th>day</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.1095</td>\n",
       "      <td>1.111100</td>\n",
       "      <td>1.10928</td>\n",
       "      <td>1.11121</td>\n",
       "      <td>1.107730</td>\n",
       "      <td>7365.0</td>\n",
       "      <td>1.10928</td>\n",
       "      <td>-0.000117</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>0.011719</td>\n",
       "      <td>Down</td>\n",
       "      <td>fast recovery</td>\n",
       "      <td>1</td>\n",
       "      <td>prior day</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>2010-05-11</td>\n",
       "      <td>00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.1089</td>\n",
       "      <td>1.109280</td>\n",
       "      <td>1.10915</td>\n",
       "      <td>1.10983</td>\n",
       "      <td>1.107420</td>\n",
       "      <td>4139.0</td>\n",
       "      <td>1.10928</td>\n",
       "      <td>-0.000117</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>0.011719</td>\n",
       "      <td>Down</td>\n",
       "      <td>fast recovery</td>\n",
       "      <td>1</td>\n",
       "      <td>prior day</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>2010-05-11</td>\n",
       "      <td>01:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.1093</td>\n",
       "      <td>1.109100</td>\n",
       "      <td>1.10979</td>\n",
       "      <td>1.11040</td>\n",
       "      <td>1.108100</td>\n",
       "      <td>3464.0</td>\n",
       "      <td>1.10915</td>\n",
       "      <td>0.000577</td>\n",
       "      <td>0.000577</td>\n",
       "      <td>0.057702</td>\n",
       "      <td>Up</td>\n",
       "      <td>fast recovery</td>\n",
       "      <td>1</td>\n",
       "      <td>prior day</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>2010-05-11</td>\n",
       "      <td>02:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.1103</td>\n",
       "      <td>1.109790</td>\n",
       "      <td>1.11042</td>\n",
       "      <td>1.11100</td>\n",
       "      <td>1.109630</td>\n",
       "      <td>2906.0</td>\n",
       "      <td>1.10979</td>\n",
       "      <td>0.000568</td>\n",
       "      <td>0.000568</td>\n",
       "      <td>0.056767</td>\n",
       "      <td>Up</td>\n",
       "      <td>fast recovery</td>\n",
       "      <td>1</td>\n",
       "      <td>prior day</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>2010-05-11</td>\n",
       "      <td>03:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.1112</td>\n",
       "      <td>1.110420</td>\n",
       "      <td>1.10990</td>\n",
       "      <td>1.11253</td>\n",
       "      <td>1.109700</td>\n",
       "      <td>5889.0</td>\n",
       "      <td>1.11042</td>\n",
       "      <td>-0.000468</td>\n",
       "      <td>0.000468</td>\n",
       "      <td>0.046829</td>\n",
       "      <td>Down</td>\n",
       "      <td>fast recovery</td>\n",
       "      <td>1</td>\n",
       "      <td>prior day</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>2010-05-11</td>\n",
       "      <td>04:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53189</th>\n",
       "      <td>53189</td>\n",
       "      <td>0.9258</td>\n",
       "      <td>0.925610</td>\n",
       "      <td>0.92641</td>\n",
       "      <td>0.92675</td>\n",
       "      <td>0.924800</td>\n",
       "      <td>8906.0</td>\n",
       "      <td>0.92560</td>\n",
       "      <td>0.000875</td>\n",
       "      <td>0.000875</td>\n",
       "      <td>0.087511</td>\n",
       "      <td>Up</td>\n",
       "      <td>fast recovery</td>\n",
       "      <td>280</td>\n",
       "      <td>post day</td>\n",
       "      <td>Friday</td>\n",
       "      <td>2023-03-17</td>\n",
       "      <td>19:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53190</th>\n",
       "      <td>53190</td>\n",
       "      <td>0.9263</td>\n",
       "      <td>0.926400</td>\n",
       "      <td>0.92580</td>\n",
       "      <td>0.92740</td>\n",
       "      <td>0.925690</td>\n",
       "      <td>6548.0</td>\n",
       "      <td>0.92641</td>\n",
       "      <td>-0.000658</td>\n",
       "      <td>0.000658</td>\n",
       "      <td>0.065846</td>\n",
       "      <td>Down</td>\n",
       "      <td>fast recovery</td>\n",
       "      <td>280</td>\n",
       "      <td>post day</td>\n",
       "      <td>Friday</td>\n",
       "      <td>2023-03-17</td>\n",
       "      <td>20:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53191</th>\n",
       "      <td>53191</td>\n",
       "      <td>0.9251</td>\n",
       "      <td>0.925900</td>\n",
       "      <td>0.92280</td>\n",
       "      <td>0.92660</td>\n",
       "      <td>0.922755</td>\n",
       "      <td>402.0</td>\n",
       "      <td>0.92580</td>\n",
       "      <td>-0.003240</td>\n",
       "      <td>0.003240</td>\n",
       "      <td>0.324044</td>\n",
       "      <td>Down</td>\n",
       "      <td>fast recovery</td>\n",
       "      <td>280</td>\n",
       "      <td>post day</td>\n",
       "      <td>Friday</td>\n",
       "      <td>2023-03-17</td>\n",
       "      <td>21:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53192</th>\n",
       "      <td>53192</td>\n",
       "      <td>0.9227</td>\n",
       "      <td>0.923000</td>\n",
       "      <td>0.92270</td>\n",
       "      <td>0.92310</td>\n",
       "      <td>0.922344</td>\n",
       "      <td>449.0</td>\n",
       "      <td>0.92280</td>\n",
       "      <td>-0.000108</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.010837</td>\n",
       "      <td>Down</td>\n",
       "      <td>fast recovery</td>\n",
       "      <td>280</td>\n",
       "      <td>post day</td>\n",
       "      <td>Friday</td>\n",
       "      <td>2023-03-17</td>\n",
       "      <td>22:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53193</th>\n",
       "      <td>53193</td>\n",
       "      <td>0.9227</td>\n",
       "      <td>0.922591</td>\n",
       "      <td>0.92280</td>\n",
       "      <td>0.92300</td>\n",
       "      <td>0.922400</td>\n",
       "      <td>436.0</td>\n",
       "      <td>0.92270</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.010838</td>\n",
       "      <td>Up</td>\n",
       "      <td>fast recovery</td>\n",
       "      <td>280</td>\n",
       "      <td>post day</td>\n",
       "      <td>Friday</td>\n",
       "      <td>2023-03-17</td>\n",
       "      <td>23:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>53194 rows Ã— 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0      vw         o        c        h         l       n  \\\n",
       "0               0  1.1095  1.111100  1.10928  1.11121  1.107730  7365.0   \n",
       "1               1  1.1089  1.109280  1.10915  1.10983  1.107420  4139.0   \n",
       "2               2  1.1093  1.109100  1.10979  1.11040  1.108100  3464.0   \n",
       "3               3  1.1103  1.109790  1.11042  1.11100  1.109630  2906.0   \n",
       "4               4  1.1112  1.110420  1.10990  1.11253  1.109700  5889.0   \n",
       "...           ...     ...       ...      ...      ...       ...     ...   \n",
       "53189       53189  0.9258  0.925610  0.92641  0.92675  0.924800  8906.0   \n",
       "53190       53190  0.9263  0.926400  0.92580  0.92740  0.925690  6548.0   \n",
       "53191       53191  0.9251  0.925900  0.92280  0.92660  0.922755   402.0   \n",
       "53192       53192  0.9227  0.923000  0.92270  0.92310  0.922344   449.0   \n",
       "53193       53193  0.9227  0.922591  0.92280  0.92300  0.922400   436.0   \n",
       "\n",
       "       prev_close  daily_return  abs_daily_return  pct_change direction  \\\n",
       "0         1.10928     -0.000117          0.000117    0.011719      Down   \n",
       "1         1.10928     -0.000117          0.000117    0.011719      Down   \n",
       "2         1.10915      0.000577          0.000577    0.057702        Up   \n",
       "3         1.10979      0.000568          0.000568    0.056767        Up   \n",
       "4         1.11042     -0.000468          0.000468    0.046829      Down   \n",
       "...           ...           ...               ...         ...       ...   \n",
       "53189     0.92560      0.000875          0.000875    0.087511        Up   \n",
       "53190     0.92641     -0.000658          0.000658    0.065846      Down   \n",
       "53191     0.92580     -0.003240          0.003240    0.324044      Down   \n",
       "53192     0.92280     -0.000108          0.000108    0.010837      Down   \n",
       "53193     0.92270      0.000108          0.000108    0.010838        Up   \n",
       "\n",
       "            Recovery  outlier_id   day type      day        Date      Time  \n",
       "0      fast recovery           1  prior day  Tuesday  2010-05-11  00:00:00  \n",
       "1      fast recovery           1  prior day  Tuesday  2010-05-11  01:00:00  \n",
       "2      fast recovery           1  prior day  Tuesday  2010-05-11  02:00:00  \n",
       "3      fast recovery           1  prior day  Tuesday  2010-05-11  03:00:00  \n",
       "4      fast recovery           1  prior day  Tuesday  2010-05-11  04:00:00  \n",
       "...              ...         ...        ...      ...         ...       ...  \n",
       "53189  fast recovery         280   post day   Friday  2023-03-17  19:00:00  \n",
       "53190  fast recovery         280   post day   Friday  2023-03-17  20:00:00  \n",
       "53191  fast recovery         280   post day   Friday  2023-03-17  21:00:00  \n",
       "53192  fast recovery         280   post day   Friday  2023-03-17  22:00:00  \n",
       "53193  fast recovery         280   post day   Friday  2023-03-17  23:00:00  \n",
       "\n",
       "[53194 rows x 18 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "data = pd.read_csv('USDCHF_hourly_20.csv')\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'iloc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 47\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m sequences, np\u001b[38;5;241m.\u001b[39marray(direction_targets), np\u001b[38;5;241m.\u001b[39marray(recovery_targets)\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# Create sequences\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m sequences, direction_targets, recovery_targets \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_sequences_per_outlier\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_columns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# Function to apply padding strategy\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_reflect_padding\u001b[39m(sequences, max_length):\n",
      "Cell \u001b[0;32mIn[4], line 31\u001b[0m, in \u001b[0;36mcreate_sequences_per_outlier\u001b[0;34m(input_data, output_data, feature_columns, seq_length)\u001b[0m\n\u001b[1;32m     29\u001b[0m scaler \u001b[38;5;241m=\u001b[39m MinMaxScaler()\n\u001b[1;32m     30\u001b[0m input_features \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mfit_transform(input_seq[feature_columns])\n\u001b[0;32m---> 31\u001b[0m \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43minput_features\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miloc\u001b[49m[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m48\u001b[39m:]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Check if there are enough rows in the output data\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(output_seq) \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m seq_length:\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;66;03m# Get direction and recovery targets for the first 24 data points of the post day\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'iloc'"
     ]
    }
   ],
   "source": [
    "# Preprocess the data\n",
    "# Create target variables\n",
    "data['direction_target'] = data['direction'].apply(lambda x: 1 if x == 'Up' else 0)\n",
    "data['recovery_target'] = data['Recovery'].apply(lambda x: 1 if x == 'fast recovery' else 0)\n",
    "data.drop(columns=['direction', 'Recovery'], inplace=True)\n",
    "\n",
    "# Filter the data\n",
    "input_data = data[data['day type'].isin(['prior day', 'outlier day'])]\n",
    "output_data = data[data['day type'] == 'post day']\n",
    "\n",
    "# Ensure the data is sorted by Date and Time\n",
    "input_data = input_data.sort_values(by=['outlier_id', 'Date', 'Time'])\n",
    "output_data = output_data.sort_values(by=['outlier_id', 'Date', 'Time'])\n",
    "\n",
    "feature_columns = ['vw', 'c', 'daily_return', 'n', 'direction_target', 'CWT_Mean']\n",
    "\n",
    "def create_sequences_per_outlier(input_data, output_data, feature_columns, seq_length=24):\n",
    "    sequences = []\n",
    "    direction_targets = []\n",
    "    recovery_targets = []\n",
    "    \n",
    "    unique_ids = input_data['outlier_id'].unique()\n",
    "    \n",
    "    for oid in unique_ids:\n",
    "        input_seq = input_data[input_data['outlier_id'] == oid]\n",
    "        output_seq = output_data[output_data['outlier_id'] == oid]\n",
    "\n",
    "        # Normalize features\n",
    "        scaler = MinMaxScaler()\n",
    "        input_features = scaler.fit_transform(input_seq[feature_columns])\n",
    "\n",
    "        # Check if there are enough rows in the output data\n",
    "        if len(output_seq) >= seq_length:\n",
    "            # Get direction and recovery targets for the first 24 data points of the post day\n",
    "            directions = output_seq['direction_target'].iloc[:seq_length].values\n",
    "            recoveries = output_seq['recovery_target'].iloc[:seq_length].values\n",
    "\n",
    "            # Store sequences and targets as arrays\n",
    "            sequences.append(input_features)\n",
    "            direction_targets.append(directions)\n",
    "            recovery_targets.append(recoveries)\n",
    "            \n",
    "    return sequences, np.array(direction_targets), np.array(recovery_targets)\n",
    "\n",
    "# Create sequences\n",
    "sequences, direction_targets, recovery_targets = create_sequences_per_outlier(input_data, output_data, feature_columns)\n",
    "\n",
    "# Function to apply padding strategy\n",
    "def apply_reflect_padding(sequences, max_length):\n",
    "    padded_sequences = []\n",
    "    for seq in sequences:\n",
    "        if len(seq) < max_length:\n",
    "            # Calculate the number of rows needed to reach max_length\n",
    "            padding_size = max_length - len(seq)\n",
    "            # Create padding by reflecting the sequence\n",
    "            if padding_size <= len(seq):\n",
    "                padding = np.flipud(seq[:padding_size])\n",
    "            else:\n",
    "                # If padding_size is greater than the sequence length, repeat reflection\n",
    "                repeat_n = int(np.ceil(padding_size / len(seq)))\n",
    "                reflected_part = np.flipud(seq)\n",
    "                padding = np.tile(reflected_part, (repeat_n, 1))[:padding_size]\n",
    "            padded_sequence = np.vstack([seq, padding])\n",
    "        else:\n",
    "            padded_sequence = seq[:max_length]  # Truncate to max_length if necessary\n",
    "        padded_sequences.append(padded_sequence)\n",
    "    return np.array(padded_sequences)\n",
    "\n",
    "# Example: Mean padding\n",
    "max_length = max(len(seq) for seq in sequences)  # Find max length to pad\n",
    "X = apply_reflect_padding(sequences, max_length)\n",
    "\n",
    "# Split the data into training and testing sets based on outlier IDs\n",
    "outlier_ids = input_data['outlier_id'].unique()\n",
    "train_ids, test_ids = train_test_split(outlier_ids, test_size=0.3, random_state=123)\n",
    "\n",
    "# Create indices for the sequences\n",
    "train_idx = [i for i, oid in enumerate(outlier_ids) if oid in train_ids]\n",
    "test_idx = [i for i, oid in enumerate(outlier_ids) if oid in test_ids]\n",
    "\n",
    "X_train = X[train_idx]\n",
    "X_test = X[test_idx]\n",
    "y_train_dir = direction_targets[train_idx]\n",
    "y_test_dir = direction_targets[test_idx]\n",
    "y_train_rec = recovery_targets[train_idx]\n",
    "y_test_rec = recovery_targets[test_idx]\n",
    "\n",
    "print(f\"X_train shape after adjustment: {X_train.shape}\")\n",
    "print(f\"y_train_dir shape after adjustment: {y_train_dir.shape}\")\n",
    "print(f\"y_train_rec shape after adjustment: {y_train_rec.shape}\")\n",
    "print(f\"X_test shape after adjustment: {X_test.shape}\")\n",
    "print(f\"y_test_dir shape after adjustment: {y_test_dir.shape}\")\n",
    "print(f\"y_test_rec shape after adjustment: {y_test_rec.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_one_hot(y, num_classes):\n",
    "    return np.array([to_categorical(y_i, num_classes=num_classes) for y_i in y])\n",
    "\n",
    "# Convert target labels to one-hot encoded format\n",
    "y_train_dir_one_hot = convert_to_one_hot(y_train_dir, num_classes=2)\n",
    "y_test_dir_one_hot = convert_to_one_hot(y_test_dir, num_classes=2)\n",
    "\n",
    "def slice_last_timesteps(x):\n",
    "    return x[:, :24, :]\n",
    "\n",
    "# Define the LSTM model for direction prediction with fixed 24 time step outputs\n",
    "model_direction = Sequential()\n",
    "model_direction.add(LSTM(100, return_sequences=True, input_shape=(None, X_train.shape[-1])))  # Input shape matches features count\n",
    "model_direction.add(Dropout(0.3))\n",
    "model_direction.add(LSTM(100, return_sequences=True))\n",
    "model_direction.add(Dropout(0.3))\n",
    "model_direction.add(Lambda(slice_last_timesteps))  # Slice the first 24 time steps\n",
    "model_direction.add(TimeDistributed(Dense(2, activation='softmax')))\n",
    "\n",
    "# Compile the model\n",
    "model_direction.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model_direction.fit(X_train, y_train_dir_one_hot, epochs=100, batch_size=32, validation_data=(X_test, y_test_dir_one_hot))\n",
    "\n",
    "\n",
    "\n",
    "# # Build the LSTM model for recovery prediction\n",
    "# model_recovery = Sequential()\n",
    "# model_recovery.add(LSTM(50, return_sequences=True, input_shape=(None, 1)))  # Accept variable input lengths\n",
    "# model_recovery.add(Dropout(0.2))\n",
    "# model_recovery.add(LSTM(50))\n",
    "# model_recovery.add(Dropout(0.2))\n",
    "# model_recovery.add(Dense(48, activation='relu'))  # Prepare to reshape for 24 time step output\n",
    "# model_recovery.add(Reshape((24, 2)))  # Reshape output to 24 time steps\n",
    "# model_recovery.add(TimeDistributed(Dense(2, activation='softmax')))\n",
    "\n",
    "# # Compile the model\n",
    "# model_recovery.compile(optimizer=Adam(learning_rate=0.005), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# # Train the model\n",
    "# model_recovery.fit(X_train, y_train_rec, epochs=100, batch_size=32, validation_data=(X_test, y_test_rec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Make predictions on the test set\n",
    "y_test_pred_prob = model_direction.predict(X_test)\n",
    "\n",
    "# 2. Convert predictions and true labels from one-hot to class labels\n",
    "y_test_pred = np.argmax(y_test_pred_prob, axis=-1)\n",
    "y_test_true = np.argmax(y_test_dir_one_hot, axis=-1)\n",
    "\n",
    "# Flatten arrays to make them 1D for metric calculations\n",
    "y_test_pred_flat = y_test_pred.flatten()\n",
    "y_test_true_flat = y_test_true.flatten()\n",
    "\n",
    "# 3. Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_test_true_flat, y_test_pred_flat)\n",
    "precision = precision_score(y_test_true_flat, y_test_pred_flat)\n",
    "recall = recall_score(y_test_true_flat, y_test_pred_flat)\n",
    "f1 = f1_score(y_test_true_flat, y_test_pred_flat)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Direction Prediction Accuracy: 0.5575396418571472 (Changing Random Seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data\n",
    "data['direction_target'] = data['direction'].apply(lambda x: 1 if x == 'Up' else 0)\n",
    "data['recovery_target'] = data['Recovery'].apply(lambda x: 1 if x == 'fast recovery' else 0)\n",
    "data.drop(columns=['direction', 'Recovery'], inplace=True)\n",
    "\n",
    "# Filter the data\n",
    "input_data = data[data['day type'].isin(['prior day', 'outlier day'])]\n",
    "output_data = data[data['day type'] == 'post day']\n",
    "\n",
    "# Ensure the data is sorted by Date and Time\n",
    "input_data = input_data.sort_values(by=['outlier_id', 'Date', 'Time'])\n",
    "output_data = output_data.sort_values(by=['outlier_id', 'Date', 'Time'])\n",
    "\n",
    "feature_columns = ['vw', 'c', 'daily_return', 'n', 'direction_target', 'CWT_Mean']\n",
    "\n",
    "def create_sequences_per_outlier(input_data, output_data, feature_columns, seq_length=48):\n",
    "    sequences = []\n",
    "    direction_targets = []\n",
    "    recovery_targets = []\n",
    "    \n",
    "    unique_ids = input_data['outlier_id'].unique()\n",
    "    \n",
    "    for oid in unique_ids:\n",
    "        input_seq = input_data[input_data['outlier_id'] == oid]\n",
    "        output_seq = output_data[output_data['outlier_id'] == oid]\n",
    "\n",
    "        # Normalize features\n",
    "        scaler = MinMaxScaler()\n",
    "        input_features = scaler.fit_transform(input_seq[feature_columns])\n",
    "\n",
    "        # Check if there are enough rows in the input data\n",
    "        if len(input_features) >= seq_length:\n",
    "            # Use only the last 48 data points of the input features\n",
    "            input_features = input_features[-seq_length:]\n",
    "\n",
    "            # Get direction and recovery targets for the first 24 data points of the post day\n",
    "            if len(output_seq) >= 24:  # Ensure there are enough data points in output_seq\n",
    "                directions = output_seq['direction_target'].iloc[:24].values\n",
    "                recoveries = output_seq['recovery_target'].iloc[:24].values\n",
    "\n",
    "                # Store sequences and targets as arrays\n",
    "                sequences.append(input_features)\n",
    "                direction_targets.append(directions)\n",
    "                recovery_targets.append(recoveries)\n",
    "            \n",
    "    return sequences, np.array(direction_targets), np.array(recovery_targets)\n",
    "\n",
    "# Create sequences\n",
    "sequences, direction_targets, recovery_targets = create_sequences_per_outlier(input_data, output_data, feature_columns)\n",
    "\n",
    "# Convert to numpy array for model input\n",
    "X = np.array(sequences)\n",
    "\n",
    "# Split the data into training and testing sets based on outlier IDs\n",
    "outlier_ids = input_data['outlier_id'].unique()\n",
    "train_ids, test_ids = train_test_split(outlier_ids, test_size=0.3, random_state=123)\n",
    "\n",
    "# Create indices for the sequences\n",
    "train_idx = [i for i, oid in enumerate(outlier_ids) if oid in train_ids]\n",
    "test_idx = [i for i, oid in enumerate(outlier_ids) if oid in test_ids]\n",
    "\n",
    "X_train = X[train_idx]\n",
    "X_test = X[test_idx]\n",
    "y_train_dir = direction_targets[train_idx]\n",
    "y_test_dir = direction_targets[test_idx]\n",
    "y_train_rec = recovery_targets[train_idx]\n",
    "y_test_rec = recovery_targets[test_idx]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
