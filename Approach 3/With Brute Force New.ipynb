{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from pandas.tseries.offsets import BDay\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error\n",
    "from tensorflow.keras.preprocessing.sequence import TimeseriesGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.stats import linregress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the API key and base URL\n",
    "api_key = 'beBybSi8daPgsTp5yx5cHtHpYcrjp5Jq'\n",
    "\n",
    "# Define the currency pairs and years\n",
    "currency_pairs = [\"USDEUR\", \"USDCAD\", \"USDCHF\", \"USDGBP\", \"USDAUD\"]\n",
    "years = range(2022, 2024)\n",
    "num_of_outliers_per_year = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_daily_return(df):\n",
    "    # Use pct_change() to calculate the percentage change in 'c' (close prices)\n",
    "    df['daily_return'] = df['c'].pct_change()\n",
    "    df['abs_daily_return'] = df['daily_return'].abs()\n",
    "    return df\n",
    "\n",
    "def get_top_outliers(df, n=num_of_outliers_per_year):\n",
    "    return df.nlargest(n, 'abs_daily_return')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize DataFrames\n",
    "full_data = pd.DataFrame()\n",
    "outliers_data = pd.DataFrame()\n",
    "\n",
    "# Loop over each currency pair and year\n",
    "for pair in currency_pairs:\n",
    "    for year in years:\n",
    "        # Format the API endpoint\n",
    "        start_date = f'{year}-01-01'\n",
    "        end_date = f'{year}-12-31'\n",
    "        url = f\"https://api.polygon.io/v2/aggs/ticker/C:{pair}/range/1/day/{start_date}/{end_date}?adjusted=true&sort=asc&limit=50000&apiKey={api_key}\"\n",
    "        \n",
    "        # Make the API request\n",
    "        response = requests.get(url)\n",
    "        data = response.json()\n",
    "        \n",
    "        # Check if the request was successful\n",
    "        if response.status_code == 200 and 'results' in data:\n",
    "            # Load data into a DataFrame\n",
    "            df = pd.DataFrame(data['results'])\n",
    "            # Convert timestamps\n",
    "            df['date'] = pd.to_datetime(df['t'], unit='ms')\n",
    "            df.drop(columns=['t'], inplace=True)\n",
    "\n",
    "            df = df[df['date'].dt.weekday < 5]  # Only include weekdays\n",
    "            # Calculating returns\n",
    "            df = calculate_daily_return(df)\n",
    "\n",
    "            # Append the data to the full_data DataFrame for the current currency pair\n",
    "            df['year'] = year\n",
    "            df['day'] = df['date'].dt.day_name()\n",
    "            df['pair'] = pair  # Add the currency pair identifier\n",
    "\n",
    "            # Find the top 10 outliers based on absolute values of the daily return value\n",
    "            top_outliers = get_top_outliers(df, num_of_outliers_per_year)\n",
    "            outlier_dates = top_outliers['date']\n",
    "\n",
    "            # Create a new column 'is_outlier' in the full_data DataFrame\n",
    "            df['is_outlier'] = df['date'].isin(outlier_dates).astype(int)\n",
    "            full_data = pd.concat([full_data, df], ignore_index=True)\n",
    "            \n",
    "            # Append outliers to the outliers_data DataFrame for the current currency pair\n",
    "            top_outliers['year'] = year\n",
    "            outliers_data = pd.concat([outliers_data, top_outliers], ignore_index=True)\n",
    "        \n",
    "sorted_full_data = full_data.sort_values(by=\"date\")\n",
    "sorted_outliers_data = outliers_data.sort_values(by=\"date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert dates in dataset to datetime objects\n",
    "sorted_outliers_data['date'] = pd.to_datetime(sorted_outliers_data['date'])\n",
    "\n",
    "date_ranges = pd.DataFrame({\n",
    "    \"start_date\": sorted_outliers_data['date'] - BDay(14), # To predict X days, keep this as X-1 (as 1 day of outlier will be considered in LSTM input)\n",
    "    \"end_date\": sorted_outliers_data['date'] + BDay(15),\n",
    "    \"outlier_date\": sorted_outliers_data['date'],\n",
    "    \"outlier_price\": sorted_outliers_data['c'],\n",
    "    \"daily_return\": sorted_outliers_data['daily_return'],\n",
    "    \"currency_pair\": sorted_outliers_data['pair']\n",
    "})\n",
    "\n",
    "date_ranges.reset_index(drop=True, inplace=True)\n",
    "date_ranges.sort_values(by=\"outlier_date\")\n",
    "date_ranges.drop_duplicates(subset='outlier_date', keep='first', inplace=True)\n",
    "\n",
    "date_ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_daily_data(pair, start_date, end_date, api_key):\n",
    "    formatted_start_date = start_date.strftime('%Y-%m-%d')\n",
    "    formatted_end_date = end_date.strftime('%Y-%m-%d')\n",
    "\n",
    "    url = f\"https://api.polygon.io/v2/aggs/ticker/C:{pair}/range/1/day/{formatted_start_date}/{formatted_end_date}?adjusted=true&sort=asc&apiKey={api_key}\"\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Failed to fetch data: {response.status_code} - {response.text}\")\n",
    "        return None\n",
    "\n",
    "    response_data = response.json()\n",
    "\n",
    "    if 'results' not in response_data:\n",
    "        print(f\"No 'results' in response: {response_data}\")\n",
    "        return None\n",
    "\n",
    "    df = pd.DataFrame(response_data['results'])\n",
    "    df['date'] = pd.to_datetime(df['t'], unit='ms')\n",
    "    df.drop(columns=['t'], inplace=True)\n",
    "\n",
    "    daily_data = calculate_daily_return(df)\n",
    "    daily_data['currency_pair'] = pair\n",
    "    daily_data.set_index('date', inplace=True)\n",
    "\n",
    "    return daily_data\n",
    "\n",
    "def fetch_and_process_daily_data(pair, start_date, end_date, api_key):\n",
    "    daily_data = fetch_daily_data(pair, start_date, end_date, api_key)\n",
    "\n",
    "    if daily_data is None:\n",
    "        print(\"No data fetched\")\n",
    "        return None\n",
    "\n",
    "    daily_data.reset_index(inplace=True)\n",
    "    return daily_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data_and_train_model(daily_data):\n",
    "    \"\"\"Processes daily data, trains an LSTM model, and returns the model and scaler.\"\"\"\n",
    "    # Filter out weekends\n",
    "    daily_data = daily_data[~daily_data['date'].dt.weekday.isin([5, 6])]\n",
    "\n",
    "    # Sort data by date\n",
    "    daily_data.sort_values(by='date', ascending=True, inplace=True)\n",
    "\n",
    "    # Fill missing values\n",
    "    daily_data.fillna(method='bfill', inplace=True)\n",
    "    daily_data.fillna(method='ffill', inplace=True)\n",
    "\n",
    "    # Split the dataset into train and test sets\n",
    "    train_set = daily_data.iloc[:15].reset_index(drop=True)\n",
    "    test_set = daily_data.iloc[15:].reset_index(drop=True)\n",
    "\n",
    "    # Normalize the data using only the training data\n",
    "    scaler = MinMaxScaler()\n",
    "    train_scaled = scaler.fit_transform(train_set[[\"c\"]])\n",
    "\n",
    "    # Prepare data for LSTM model\n",
    "    sequence_length = 12\n",
    "    train_generator = TimeseriesGenerator(train_scaled, train_scaled, length=sequence_length, batch_size=1)\n",
    "\n",
    "    # Define and compile LSTM model\n",
    "    model = Sequential([\n",
    "        LSTM(64, activation='relu', input_shape=(sequence_length, 1), kernel_initializer='orthogonal'),\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=0.01), loss='mean_squared_error')\n",
    "\n",
    "    # Fit the model\n",
    "    model.fit(train_generator, epochs=100, verbose=0)\n",
    "\n",
    "    # Prepare the last sequence for forecasting\n",
    "    last_sequence = train_scaled[-sequence_length:]\n",
    "\n",
    "    # Forecast the next steps\n",
    "    forecast_steps = len(test_set)\n",
    "    predictions_scaled = []\n",
    "    for _ in range(forecast_steps):\n",
    "        last_sequence_reshaped = last_sequence.reshape((1, sequence_length, 1))\n",
    "        next_step_pred = model.predict(last_sequence_reshaped, verbose=0)\n",
    "        predictions_scaled.append(next_step_pred.ravel()[0])\n",
    "        last_sequence = np.roll(last_sequence, -1)\n",
    "        last_sequence[-1] = next_step_pred\n",
    "\n",
    "    # Inverse transform predictions\n",
    "    predictions_inv = scaler.inverse_transform(np.array(predictions_scaled).reshape(-1, 1))\n",
    "\n",
    "    return predictions_inv, forecast_steps, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_market_trends(row, actuals, predictions_inv, test_set, daily_data):\n",
    "    \"\"\"Analyzes market trends and makes trade decisions based on the LSTM model's predictions and actual market data,\n",
    "       calculating the daily return dynamically.\"\"\"\n",
    "    # Calculate daily return for the outlier date\n",
    "    historical_data = daily_data.loc[daily_data['date'] <= row['outlier_date']]\n",
    "    historical_data['daily_return'] = historical_data['c'].pct_change()\n",
    "    daily_return = historical_data.loc[historical_data['date'] == row['outlier_date'], 'daily_return'].item()\n",
    "\n",
    "    # Calculate actual market trend\n",
    "    actual_days = np.arange(1, len(actuals) + 1)\n",
    "    actual_slope, _, _, _, _ = linregress(actual_days, actuals)\n",
    "    if daily_return > 0:  # Positive outlier\n",
    "        actual_market_trend = \"Momentum Continuation\" if actual_slope > 0 else \"Mean Reversion\"\n",
    "    else:  # Negative outlier\n",
    "        actual_market_trend = \"Momentum Continuation\" if actual_slope < 0 else \"Mean Reversion\"\n",
    "\n",
    "    # Determine the type of outlier\n",
    "    is_positive_outlier = daily_return > 0\n",
    "    outlier_type = \"Positive\" if is_positive_outlier else \"Negative\"\n",
    "\n",
    "    # Create an array for time (days 1 to len(predictions_inv))\n",
    "    days = np.arange(1, len(predictions_inv) + 1)\n",
    "    slope, _, _, _, _ = linregress(days, predictions_inv.ravel())\n",
    "\n",
    "    # Trade logic\n",
    "    trade_initiated = False\n",
    "    entry_price = None\n",
    "    exit_price = None\n",
    "    entry_date = None\n",
    "    exit_date = None\n",
    "    profit = 0\n",
    "    days_held = 0\n",
    "    position_type = None\n",
    "\n",
    "    if slope > 0:\n",
    "        market_trend = \"Momentum Continuation\" if outlier_type == 'Positive' else \"Mean Reversion\"\n",
    "        exit_idx = np.argmax(predictions_inv)\n",
    "        entry_idx = np.argmin(predictions_inv[:exit_idx + 1])\n",
    "        trade_type = \"Long\"\n",
    "    else:\n",
    "        market_trend = \"Mean Reversion\" if outlier_type == 'Positive' else \"Momentum Continuation\"\n",
    "        entry_idx = np.argmax(predictions_inv)\n",
    "        exit_idx = np.argmin(predictions_inv[entry_idx:]) + entry_idx\n",
    "        trade_type = \"Short\"\n",
    "\n",
    "    if trade_type == \"Long\":\n",
    "        entry_price = predictions_inv[entry_idx]\n",
    "        exit_price = predictions_inv[exit_idx]\n",
    "        entry_date = test_set.iloc[entry_idx]['date']\n",
    "        exit_date = test_set.iloc[exit_idx]['date']\n",
    "        profit = (exit_price - entry_price) / entry_price * 100\n",
    "        days_held = exit_idx - entry_idx\n",
    "        position_type = \"Long\"\n",
    "        trade_initiated = True\n",
    "    else:\n",
    "        entry_price = predictions_inv[entry_idx]\n",
    "        exit_price = predictions_inv[exit_idx]\n",
    "        entry_date = test_set.iloc[entry_idx]['date']\n",
    "        exit_date = test_set.iloc[exit_idx]['date']\n",
    "        profit = (entry_price - exit_price) / entry_price * 100\n",
    "        days_held = exit_idx - entry_idx\n",
    "        position_type = \"Short\"\n",
    "        trade_initiated = True\n",
    "\n",
    "    # Compile results\n",
    "    trade_results = {\n",
    "        'Type': outlier_type,\n",
    "        'Actual Market Trend': actual_market_trend,\n",
    "        'Predicted Market Trend': market_trend,\n",
    "        'Position Type': position_type,\n",
    "        'Entry Date': entry_date,\n",
    "        'Entry Price': entry_price,\n",
    "        'Exit Date': exit_date,\n",
    "        'Exit Price': exit_price,\n",
    "        'Trading Days': days_held,\n",
    "        'Profit': profit,\n",
    "        'Trade Initiated': trade_initiated\n",
    "    }\n",
    "\n",
    "    return trade_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_values(daily_data, row):\n",
    "\tpredictions_inv, forecast_steps, test_set = process_data_and_train_model(daily_data)\n",
    "\n",
    "\t# Actual values for comparison\n",
    "\tactuals = test_set[\"c\"].values[:forecast_steps]\n",
    "\t\n",
    "\t# Calculate MAPE (Mean Absolute Percentage Error)\n",
    "\tmse = mean_squared_error(actuals, predictions_inv)\n",
    "\trmse = np.sqrt(mse)\n",
    "\tmape = mean_absolute_percentage_error(actuals, predictions_inv)\n",
    "\taccuracy = np.round(100 - (mape * 100), 2)\n",
    "\n",
    "\tresults = analyze_market_trends(row, actuals, predictions_inv, test_set, daily_data)\n",
    "\tresults[\"model_RMSE\"] = rmse\n",
    "\tresults[\"model_accuracy\"] = accuracy\n",
    "\treturn results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list to store the final results\n",
    "final_results_dict = {'Date': [], \n",
    "\t'Pair': [], 'Price': [], 'Type': [], 'Actual Market Trend': [], 'Predicted Market Trend': [], 'Position Type': [], 'Entry Date': [], \n",
    "\t'Entry Price': [], 'Exit Date': [], 'Exit Price': [], 'Trading Days': [], 'Profit': [], 'model_RMSE': [], 'model_accuracy': [],\n",
    "\t\n",
    "\t'Counter Pair': [], 'Counter Price': [], 'Counter Type': [], 'Counter Actual Market Trend': [], 'Counter Predicted Market Trend': [],\n",
    "\t'Counter Position Type': [], 'Counter Entry Date': [], 'Counter Entry Price': [], 'Counter Exit Date': [], 'Counter Exit Price': [],\n",
    "\t'Counter Trading Days': [], 'Counter Profit': [], 'Counter model_RMSE': [], 'Counter model_accuracy': [] \n",
    "}\n",
    "\n",
    "# List of currency pairs to ensure that only unique pairs are processed\n",
    "unique_pairs = [\"USDEUR\", \"USDCAD\", \"USDCHF\", \"USDGBP\", \"USDAUD\", \"USDNZD\", \"USDSGD\", \n",
    "                \"USDPLN\", \"USDILS\", \"USDBRL\", \"USDSEK\", \"USDNOK\", \"USDMXN\", \"USDCZK\"]\n",
    "\n",
    "# Iterate through each record in the outlier data\n",
    "for idx, row in date_ranges.iterrows():\n",
    "    reference_pair = row['currency_pair']\n",
    "    start_date = pd.Timestamp(row['start_date'])\n",
    "    end_date = pd.Timestamp(row['end_date']) + pd.Timedelta(days=1)\n",
    "    outlier_date = pd.Timestamp(row['outlier_date'])\n",
    "\n",
    "    # Retrieve and process daily data for the specified date range\n",
    "    daily_data = fetch_and_process_daily_data(reference_pair, start_date, end_date, api_key)\n",
    "\n",
    "    if daily_data is None:\n",
    "        print(f\"No data fetched for outlier_id: {idx + 1}\")\n",
    "        continue  # Skip to the next iteration if no data is available\n",
    "\n",
    "    results = get_values(daily_data, row)\n",
    "    \n",
    "    # Store results from the fetched data\n",
    "    final_results_dict['Date'].append(outlier_date)\n",
    "    final_results_dict['Pair'].append(reference_pair)\n",
    "    final_results_dict['Price'].append(row['outlier_price'])\n",
    "\n",
    "    # Exclude 'Trade Initiated' from results\n",
    "    for key in results:\n",
    "        if key == 'Trade Initiated':\n",
    "            continue\n",
    "        final_results_dict[key].append(results[key])\n",
    "\n",
    "    # Additional processing if a trade was initiated\n",
    "    if results['Trade Initiated']:\n",
    "        possible_pairs = []\n",
    "        opposite_position = \"long\" if results[\"Position Type\"] == \"short\" else \"short\"\n",
    "\n",
    "        for pair in unique_pairs:\n",
    "            if pair != reference_pair:  # Exclude the reference pair\n",
    "                daily_data_pair = fetch_and_process_daily_data(pair, start_date, end_date, api_key)\n",
    "                if daily_data_pair is None:\n",
    "                    continue\n",
    "\n",
    "                results_pair = get_values(daily_data_pair, row)\n",
    "                possible_pairs.append((pair, results_pair))\n",
    "\n",
    "        # Find pairs that meet specific conditions\n",
    "        final_pairs = []\n",
    "        for pair, results_pair in possible_pairs:\n",
    "            if results_pair[\"Position Type\"] == opposite_position and results_pair[\"RMSE\"] < 0.05:\n",
    "                final_pairs.append((pair, results_pair))\n",
    "\n",
    "        if len(final_pairs) == 0:\n",
    "            final_results_dict['Counter Pair'].append(None)\n",
    "            final_results_dict['Counter Price'].append(None)\n",
    "            for key in results:\n",
    "                if key == 'Trade Initiated':\n",
    "                    continue\n",
    "                final_results_dict[\"Counter \"+key].append(None)\n",
    "        else:\n",
    "            max_pair, max_results = max(final_pairs, key=lambda a: a[1][\"Profit\"])\n",
    "            for key in max_results:\n",
    "                if key == 'Trade Initiated':\n",
    "                    continue\n",
    "                final_results_dict[\"Counter \"+key].append(max_results[key])\n",
    "\n",
    "# Convert the dictionary of results to a DataFrame for easier analysis\n",
    "final_results_df = pd.DataFrame(final_results_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = final_results_df[(final_results_df['model_RMSE'] < 0.05)]\n",
    "filtered_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df['Final Profit'] = filtered_df['Profit'] + filtered_df['Counter Profit']\n",
    "min_profit = round(filtered_df['Final Profit'].min(), 2)\n",
    "max_profit = round(filtered_df['Final Profit'].max(), 2)\n",
    "\n",
    "print('Minimum Profit:', min_profit, '%')\n",
    "print('Maximum Profit:', max_profit, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
