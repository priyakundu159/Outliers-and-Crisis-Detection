{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9hpzSdtGyba6"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('fnew_data.csv')"
      ],
      "metadata": {
        "id": "RZ8_R1rgygGd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['Label'] = np.where(data['Close'].shift(-1) > data['Close'], 1, 0)\n",
        "\n",
        "# Feature columns and sequence length\n",
        "feature_columns = ['10_day_MA', '30_day_volatility', 'RSI']\n",
        "seq_length = 60\n",
        "\n",
        "#Filtering and sorting data\n",
        "\n",
        "\n",
        "input_data = data.sort_values(by=['Date', 'Time'])\n"
      ],
      "metadata": {
        "id": "kYwTJgHlyka_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_sequences_per_outlier(input_data, feature_columns, target_column, seq_length):\n",
        "    sequences = []\n",
        "    targets = []\n",
        "\n",
        "    unique_ids = input_data['outlier_id'].unique() if 'outlier_id' in input_data.columns else [None]\n",
        "\n",
        "    for oid in unique_ids:\n",
        "        if oid:\n",
        "            input_seq = input_data[input_data['outlier_id'] == oid]\n",
        "        else:\n",
        "            input_seq = input_data\n",
        "\n",
        "        # Normalize features\n",
        "        scaler = MinMaxScaler()\n",
        "        input_features = scaler.fit_transform(input_seq[feature_columns])\n",
        "\n",
        "        # Ensure sequence length is exactly `seq_length` for input features\n",
        "        for i in range(len(input_features) - seq_length):\n",
        "            sequence = input_features[i:i + seq_length]\n",
        "            sequences.append(sequence)\n",
        "            target = input_seq[target_column].iloc[i + seq_length]\n",
        "            targets.append(target)\n",
        "\n",
        "    return np.array(sequences), np.array(targets)"
      ],
      "metadata": {
        "id": "JDEmZE2mynN0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create sequences\n",
        "X, y = create_sequences_per_outlier(input_data, feature_columns, 'Label', seq_length)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
      ],
      "metadata": {
        "id": "iB9HyG8m1tKx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(100, return_sequences=True, input_shape=(seq_length, len(feature_columns))))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(100, return_sequences=False))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(50, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred_prob = model.predict(X_test)\n",
        "y_pred = (y_pred_prob > 0.5).astype(int)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "\n",
        "# Print the results\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")"
      ],
      "metadata": {
        "id": "SParNamy2HEf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}